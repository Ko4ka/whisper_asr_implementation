{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# List of audio file paths (up to 10 files)\n",
    "audio_file_paths = [\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/in-7035555-9587853839-20240802-155950-1722603590.21580.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/out-3036641-3133-20240802-135335-1722596015.21347.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3101-000047e6-2024-08-02-15-28-09.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3213-000044b5-2024-08-02-09-34-26.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3223-0000454f-2024-08-02-10-35-26.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3353-000048a9-2024-08-02-18-28-28.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5101-000046c7-2024-08-02-13-00-10.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5101-0000459d-2024-08-02-11-16-40.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5101-00004669-2024-08-02-12-27-31.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5102-000045ea-2024-08-02-11-40-30.wav\"\n",
    "]\n",
    "\n",
    "audio_file_paths = [\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13143_17303__2023_01_31__11_05_42_100.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13301_17384__2023_02_01__17_43_03_327.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13276_17360__2023_02_01__10_11_14_457.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13170_13171__2023_02_01__17_32_20_210.mp3\"\n",
    "]\n",
    "\n",
    "# Step 1: Transcribe the audio files\n",
    "print('Posting audio files for transcription')\n",
    "\n",
    "# Prepare the files for the transcription request\n",
    "transcription_files = [('audio_files', open(file_path, 'rb')) for file_path in audio_file_paths]\n",
    "\n",
    "try:\n",
    "    transcription_response = requests.post(\n",
    "        \"http://localhost:8000/transcribe_mono\",\n",
    "        files=transcription_files\n",
    "    )\n",
    "    transcription_response.raise_for_status()\n",
    "    transcription_data = transcription_response.json()\n",
    "    transcription_results = transcription_data[\"results\"]\n",
    "except Exception as e:\n",
    "    print(f\"Error during transcription: {e}\")\n",
    "    transcription_results = []\n",
    "finally:\n",
    "    # Close the file handles\n",
    "    for _, file_obj in transcription_files:\n",
    "        file_obj.close()\n",
    "\n",
    "print('Posting audio files for transcription -- DONE')\n",
    "\n",
    "# Inspect the transcription results for debugging\n",
    "print(\"Transcription Results:\")\n",
    "print(json.dumps(transcription_results, indent=2))\n",
    "\n",
    "# Step 2: Diarize using the transcription segments\n",
    "print('Posting audio files for diarization')\n",
    "\n",
    "# Prepare the files for the diarization request\n",
    "diarization_files = []\n",
    "transcription_segments_list = []\n",
    "valid_audio_files = []\n",
    "\n",
    "for idx, result in enumerate(transcription_results):\n",
    "    if \"segments\" in result:\n",
    "        # Add the audio file and transcription segments to the lists\n",
    "        file_path = audio_file_paths[idx]\n",
    "        diarization_files.append(('audio_files', open(file_path, 'rb')))\n",
    "        segments_json = json.dumps(result[\"segments\"])\n",
    "        transcription_segments_list.append(segments_json)\n",
    "        valid_audio_files.append(file_path)\n",
    "    else:\n",
    "        # Handle the error case\n",
    "        print(f\"Transcription failed for file: {result.get('file', 'unknown')}\")\n",
    "        print(f\"Error message: {result.get('error', 'No error message available')}\")\n",
    "\n",
    "# Ensure we have valid files to process\n",
    "if not valid_audio_files:\n",
    "    print(\"No valid transcriptions were obtained. Exiting.\")\n",
    "    exit(1)\n",
    "\n",
    "# Prepare the data parameter as a list of tuples\n",
    "data = []\n",
    "for segments_json in transcription_segments_list:\n",
    "    data.append(('transcription_segments_list', segments_json))\n",
    "# Add the num_speakers parameter (optional)\n",
    "data.append(('num_speakers', '2'))  # Optional\n",
    "\n",
    "try:\n",
    "    diarization_response = requests.post(\n",
    "        \"http://localhost:8001/diarize\",\n",
    "        files=diarization_files,\n",
    "        data=data\n",
    "    )\n",
    "    diarization_response.raise_for_status()\n",
    "    diarized_data = diarization_response.json()\n",
    "    diarized_results = diarized_data[\"results\"]\n",
    "except Exception as e:\n",
    "    print(f\"Error during diarization: {e}\")\n",
    "    diarized_results = []\n",
    "finally:\n",
    "    # Close the file handles\n",
    "    for _, file_obj in diarization_files:\n",
    "        file_obj.close()\n",
    "\n",
    "print('Posting audio files for diarization -- DONE')\n",
    "\n",
    "# Now you can process 'diarized_results' which contains the diarized segments for each file\n",
    "for diarized_result in diarized_results:\n",
    "    if \"diarized_segments\" in diarized_result:\n",
    "        file_name = diarized_result['file']\n",
    "        diarized_segments = diarized_result['diarized_segments']\n",
    "        print(f\"File: {file_name}\")\n",
    "        for segment in diarized_segments:\n",
    "            start = segment['start']\n",
    "            end = segment['end']\n",
    "            text = segment['text']\n",
    "            speaker = segment['speaker']\n",
    "            print(f\"[{start:.2f} - {end:.2f}] {speaker}: {text}\")\n",
    "        print()\n",
    "    else:\n",
    "        # Handle the error case\n",
    "        f\"Diarization failed for file: {diarized_result.get('file', 'unknown')}\"\n",
    "        f\"Error message: {diarized_result.get('error', 'No error message available')}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_file_paths = [\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13143_17303__2023_01_31__11_05_42_100.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13301_17384__2023_02_01__17_43_03_327.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13276_17360__2023_02_01__10_11_14_457.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13170_13171__2023_02_01__17_32_20_210.mp3\"\n",
    "] \n",
    "\n",
    "stereo_paths = [\n",
    "    'E:/Записи/ФСК/20210623080301062173700pri.wav'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import warnings\n",
    "import torchaudio\n",
    "from tempfile import NamedTemporaryFile\n",
    "\n",
    "#warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"whisper\")\n",
    "\n",
    "model = whisper.load_model(\"turbo\", device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load audio and pad/trim it to fit 30 seconds\n",
    "audio = whisper.load_audio(audio_file_paths[0])\n",
    "audio = whisper.pad_or_trim(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whisper.transcribe(audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torchaudio way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torchaudio\n",
    "import warnings\n",
    "import numpy as np\n",
    "from tempfile import NamedTemporaryFile\n",
    "import os\n",
    "\n",
    "# Ignore FutureWarnings from whisper\n",
    "#warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"whisper\")\n",
    "#warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"whisper\")\n",
    "\n",
    "# Load the Whisper model on GPU\n",
    "model = whisper.load_model(\"turbo\", device=\"cuda\")\n",
    "\n",
    "# Path to your stereo audio file\n",
    "stereo_path = 'E:/Записи/ФСК/20210623080301062173700pri.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your stereo audio file\n",
    "stereo_path = 'E:/Записи/ФСК/2021062309023419811401pri.wav'\n",
    "\n",
    "# Load the stereo audio file\n",
    "waveform, sample_rate = torchaudio.load(stereo_path)\n",
    "\n",
    "# Ensure the audio is stereo (2 channels)\n",
    "if waveform.shape[0] == 2:\n",
    "    # Separate channels\n",
    "    channel_0 = waveform[0].unsqueeze(0)  # Channel 0\n",
    "    channel_1 = waveform[1].unsqueeze(0)  # Channel 1\n",
    "\n",
    "    # Save each channel to a temporary file\n",
    "    with NamedTemporaryFile(suffix=\".wav\", delete=False, dir='./temp') as temp_file_0, \\\n",
    "         NamedTemporaryFile(suffix=\".wav\", delete=False, dir='./temp') as temp_file_1:\n",
    "        \n",
    "        # Save channel 0\n",
    "        torchaudio.save(temp_file_0.name, channel_0, sample_rate, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "        channel_0_path = temp_file_0.name\n",
    "        print(f\"Channel 0 saved at: {channel_0_path}\")\n",
    "\n",
    "        # Save channel 1\n",
    "        torchaudio.save(temp_file_1.name, channel_1, sample_rate, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "        channel_1_path = temp_file_1.name\n",
    "        print(f\"Channel 1 saved at: {channel_1_path}\")\n",
    "        #whisper.DecodingOptions()\n",
    "            # Transcribe each channel separately with additional options\n",
    "        print(\"Transcribing Speaker 0...\")\n",
    "        whisper.DecodingOptions()\n",
    "        result_speaker_0 = model.transcribe(\n",
    "            channel_0_path,\n",
    "            language=\"ru\",\n",
    "            initial_prompt='Звонок в компанию, это колл центр застройщика, разговор ведет сотрудник Ольга',\n",
    "            temperature= (0.0, 0.1),\n",
    "            logprob_threshold=-0.6,\n",
    "            no_speech_threshold= 0.0,\n",
    "            compression_ratio_hallucination_threshold=2.1,\n",
    "            condition_on_previous_text=True,\n",
    "            word_timestamps=True,\n",
    "            hallucination_silence_threshold=1\n",
    "        )\n",
    "\n",
    "        print(\"Transcribing Speaker 1...\")\n",
    "        result_speaker_1 = model.transcribe(\n",
    "                channel_1_path,\n",
    "                language=\"ru\",\n",
    "                initial_prompt='Звонок в компанию ФСК, это колл центр застройщика, клиент говорит о покупке квартиры',\n",
    "                temperature=(0.0, 0.1),\n",
    "                no_speech_threshold= 0.0,\n",
    "                condition_on_previous_text=True,\n",
    "                word_timestamps=True,\n",
    "                hallucination_silence_threshold=0.5\n",
    "            )\n",
    "\n",
    "        # Print transcriptions for each speaker\n",
    "        print(\"Transcription for Speaker 0:\")\n",
    "        for segment in result_speaker_0[\"segments\"]:\n",
    "            print(f\"{segment['start']}s - {segment['end']}s: {segment['text']} {segment['compression_ratio']}\")\n",
    "\n",
    "        print(\"\\nTranscription for Speaker 1:\")\n",
    "        for segment in result_speaker_1[\"segments\"]:\n",
    "            print(f\"{segment['start']}s - {segment['end']}s: {segment['text']}\")\n",
    "\n",
    "else:\n",
    "    print(\"Error: Audio is not stereo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_speaker_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunked approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from tempfile import NamedTemporaryFile\n",
    "import os\n",
    "\n",
    "# Path to your stereo audio file\n",
    "stereo_path = 'E:/Записи/ФСК/2021062309023419811401pri.wav'\n",
    "\n",
    "# Load the stereo audio file\n",
    "waveform, sample_rate = torchaudio.load(stereo_path)\n",
    "\n",
    "# Parameters\n",
    "chunk_duration = 900  # Chunk duration in seconds\n",
    "num_channels = waveform.shape[0]\n",
    "chunk_samples = chunk_duration * sample_rate  # Number of samples per chunk\n",
    "\n",
    "# Ensure the audio is stereo (2 channels)\n",
    "if num_channels == 2:\n",
    "    for channel_idx in range(num_channels):\n",
    "        # Select the channel waveform\n",
    "        channel_waveform = waveform[channel_idx].unsqueeze(0)  # Single channel waveform\n",
    "        channel_name = f\"Speaker {channel_idx}\"\n",
    "        \n",
    "        # Split into 90-second chunks\n",
    "        num_chunks = (channel_waveform.shape[1] + chunk_samples - 1) // chunk_samples\n",
    "        transcriptions = []\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start_sample = i * chunk_samples\n",
    "            end_sample = min((i + 1) * chunk_samples, channel_waveform.shape[1])\n",
    "            chunk_waveform = channel_waveform[:, start_sample:end_sample]\n",
    "            start_time = start_sample / sample_rate  # in seconds\n",
    "            end_time = end_sample / sample_rate  # in seconds\n",
    "\n",
    "            # Save each chunk to a temporary file\n",
    "            with NamedTemporaryFile(suffix=\".wav\", delete=False, dir='./temp') as temp_file:\n",
    "                torchaudio.save(temp_file.name, chunk_waveform, sample_rate, encoding=\"PCM_S\", bits_per_sample=16)\n",
    "                temp_path = temp_file.name\n",
    "            \n",
    "            # Transcribe each chunk with original timings\n",
    "            print(f\"Transcribing {channel_name}, chunk {i + 1}/{num_chunks}, from {start_time:.2f}s to {end_time:.2f}s...\")\n",
    "            whisper.DecodingOptions()\n",
    "            result = model.transcribe(\n",
    "                temp_path,\n",
    "                language=\"ru\",\n",
    "                #initial_prompt='Звонок в компанию ФСК, это колл центр застройщика' if channel_idx == 0 else 'Звонок в компанию ФСК, это колл центр застройщика, клиент говорит о покупке квартиры',\n",
    "                temperature=(0.0, 0.1),\n",
    "                no_speech_threshold=0.3,\n",
    "                suppress_tokens = [50365, 2933, 8893, 403, 1635, 10461, 40653, 413, 4775, 51, 284, 89, 453, 51864, 50366, 8567, 1435, 21403, 5627, 15363, 17781, 485, 51863],\n",
    "                condition_on_previous_text=False,\n",
    "                word_timestamps=True,\n",
    "                compression_ratio_hallucination_threshold=2.1,\n",
    "                fp16 = True\n",
    "            )\n",
    "            # Add Субтитры сделал DimaTorzok and other exceptions\n",
    "            # Collect transcriptions with original chunk timing\n",
    "            for segment in result[\"segments\"]:\n",
    "                segment['start'] += start_time\n",
    "                segment['end'] += start_time\n",
    "                transcriptions.append(segment)\n",
    "\n",
    "            # Clean up temporary file\n",
    "            os.remove(temp_path)\n",
    "\n",
    "        # Print transcriptions for the current speaker\n",
    "        print(f\"\\nTranscription for {channel_name}:\")\n",
    "        for segment in transcriptions:\n",
    "            print(f\"{segment['start']}s - {segment['end']}s: {segment['text']}  {segment['compression_ratio']}\")\n",
    "        # print(transcriptions)\n",
    "\n",
    "else:\n",
    "    print(\"Error: Audio is not stereo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import torchaudio\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the Whisper model on GPU\n",
    "model = whisper.load_model(\"turbo\", device=\"cuda\")\n",
    "\n",
    "# Path to your stereo audio file\n",
    "stereo_path = 'E:/Записи/ФСК/2021062309023419811401pri.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the stereo audio file\n",
    "waveform, sample_rate = torchaudio.load(stereo_path)\n",
    "\n",
    "# Resample the entire waveform to 16000 Hz if necessary\n",
    "target_sample_rate = 16000\n",
    "if sample_rate != target_sample_rate:\n",
    "    waveform = torchaudio.functional.resample(\n",
    "        waveform, sample_rate, target_sample_rate\n",
    "    )\n",
    "    sample_rate = target_sample_rate\n",
    "\n",
    "# Parameters\n",
    "chunk_duration = 900  # Chunk duration in seconds\n",
    "num_channels = waveform.shape[0]\n",
    "chunk_samples = int(chunk_duration * sample_rate)  # Number of samples per chunk\n",
    "\n",
    "# Ensure the audio is stereo (2 channels)\n",
    "if num_channels == 2:\n",
    "    for channel_idx in range(num_channels):\n",
    "        # Select the channel waveform\n",
    "        channel_waveform = waveform[channel_idx].unsqueeze(0)  # Shape: [1, num_samples]\n",
    "        channel_name = f\"Speaker {channel_idx}\"\n",
    "\n",
    "        # Split into chunks\n",
    "        num_samples = channel_waveform.shape[1]\n",
    "        num_chunks = (num_samples + chunk_samples - 1) // chunk_samples\n",
    "        transcriptions = []\n",
    "\n",
    "        for i in range(num_chunks):\n",
    "            start_sample = i * chunk_samples\n",
    "            end_sample = min((i + 1) * chunk_samples, num_samples)\n",
    "            chunk_waveform = channel_waveform[:, start_sample:end_sample]\n",
    "            start_time = start_sample / sample_rate  # in seconds\n",
    "\n",
    "            # Convert chunk_waveform to NumPy array\n",
    "            chunk_numpy = chunk_waveform.squeeze().numpy()\n",
    "\n",
    "            # Transcribe the chunk\n",
    "            print(\n",
    "                f\"Transcribing {channel_name}, chunk {i + 1}/{num_chunks}, from {start_time:.2f}s...\"\n",
    "            )\n",
    "\n",
    "            result = model.transcribe(\n",
    "                audio=chunk_numpy,\n",
    "                language=\"ru\",\n",
    "                temperature=(0.0, 0.1),\n",
    "                no_speech_threshold=0.3,\n",
    "                suppress_tokens=[\n",
    "                    50365, 2933, 8893, 403, 1635, 10461, 40653,\n",
    "                    413, 4775, 51, 284, 89, 453, 51864, 50366,\n",
    "                    8567, 1435, 21403, 5627, 15363, 17781, 485,\n",
    "                    51863\n",
    "                ],\n",
    "                condition_on_previous_text=False,\n",
    "                word_timestamps=True,\n",
    "                compression_ratio_hallucination_threshold=2.1,\n",
    "                fp16=True,\n",
    "            )\n",
    "\n",
    "            # Adjust the segment times\n",
    "            for segment in result[\"segments\"]:\n",
    "                segment['start'] += start_time\n",
    "                segment['end'] += start_time\n",
    "                transcriptions.append(segment)\n",
    "\n",
    "        # Print transcriptions for the current speaker\n",
    "        print(f\"\\nTranscription for {channel_name}:\")\n",
    "        for segment in transcriptions:\n",
    "            print(\n",
    "                f\"{segment['start']:.2f}s - {segment['end']:.2f}s: {segment['text']}  {segment.get('compression_ratio', '')}\"\n",
    "            )\n",
    "\n",
    "else:\n",
    "    print(\"Error: Audio is not stereo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from silero_vad import load_silero_vad, read_audio, get_speech_timestamps\n",
    "vad = load_silero_vad()\n",
    "wav = read_audio('c:/Users/Alex/whisper_asr_implementation/Drafts/temp/tmpbshce7ez.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_timestamps = get_speech_timestamps(\n",
    "  wav,\n",
    "  vad,\n",
    "  min_speech_duration_ms=400,\n",
    "  return_seconds=True,  # Return speech timestamps in seconds (default is samples)\n",
    "  sampling_rate=16000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge VAD segments that are within 0.5 seconds of each other\n",
    "def merge_vad_segments(vad_segments, merge_threshold=0.5):\n",
    "    if not vad_segments:\n",
    "        return []\n",
    "\n",
    "    merged_segments = []\n",
    "    current_segment = vad_segments[0]\n",
    "\n",
    "    for next_segment in vad_segments[1:]:\n",
    "        if next_segment['start'] - current_segment['end'] <= merge_threshold:\n",
    "            # Extend the current segment's end time\n",
    "            current_segment['end'] = next_segment['end']\n",
    "        else:\n",
    "            merged_segments.append(current_segment)\n",
    "            current_segment = next_segment\n",
    "    merged_segments.append(current_segment)\n",
    "\n",
    "    return merged_segments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load('c:/Users/Alex/whisper_asr_implementation/Drafts/temp/tmpbshce7ez.wav')\n",
    "num_channels = waveform.shape[0]\n",
    "vad_output = speech_timestamps\n",
    "# Apply merging\n",
    "vad_output = merge_vad_segments(vad_output, merge_threshold=2)\n",
    "# Process each channel separately\n",
    "for channel_idx in range(num_channels):\n",
    "    channel_waveform = waveform[channel_idx]  # Single channel waveform\n",
    "    channel_name = f\"Speaker {channel_idx}\"\n",
    "\n",
    "    transcriptions = []\n",
    "\n",
    "    # Process each VAD segment\n",
    "    for i, vad_segment in enumerate(vad_output):\n",
    "        start_time = vad_segment['start']\n",
    "        end_time = vad_segment['end']\n",
    "        start_sample = int(start_time * sample_rate)\n",
    "        end_sample = int(end_time * sample_rate)\n",
    "\n",
    "        # Extract the audio segment\n",
    "        segment_waveform = channel_waveform[start_sample:end_sample]\n",
    "\n",
    "        # Check if the segment is non-empty\n",
    "        if segment_waveform.numel() == 0:\n",
    "            continue  # Skip empty segments\n",
    "\n",
    "        # Reshape to (1, N) for a single channel\n",
    "        segment_waveform = segment_waveform.unsqueeze(0)\n",
    "\n",
    "        # Resample to 16 kHz if necessary\n",
    "        if sample_rate != 16000:\n",
    "            resampler = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
    "            segment_waveform = resampler(segment_waveform)\n",
    "\n",
    "        # Convert to numpy array as Whisper expects NumPy arrays\n",
    "        segment_waveform_np = segment_waveform.squeeze(0).numpy()\n",
    "\n",
    "        # Transcribe the segment\n",
    "        print(f\"Transcribing {channel_name}, segment {i + 1}/{len(vad_output)}, from {start_time:.2f}s to {end_time:.2f}s...\")\n",
    "\n",
    "        result = model.transcribe(\n",
    "            audio=segment_waveform_np,\n",
    "            language=\"ru\",\n",
    "            initial_prompt='Звонок в компанию ФСК, это колл центр застройщика',\n",
    "            temperature=(0.0, 0.1),\n",
    "            no_speech_threshold=0.6,\n",
    "            condition_on_previous_text=True,\n",
    "            word_timestamps=True,\n",
    "            hallucination_silence_threshold=0.1 \n",
    "        )\n",
    "\n",
    "        # Collect transcriptions with original timings\n",
    "        for segment in result[\"segments\"]:\n",
    "            # Adjust the timestamps to the original audio timeline\n",
    "            segment['start'] += start_time\n",
    "            segment['end'] += start_time\n",
    "            transcriptions.append(segment)\n",
    "\n",
    "    # Print transcriptions for the current speaker\n",
    "    print(f\"\\nTranscription for {channel_name}:\")\n",
    "    for segment in transcriptions:\n",
    "        print(f\"{segment['start']:.2f}s - {segment['end']:.2f}s: {segment['text']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = whisper.load_audio('c:/Users/Alex/whisper_asr_implementation/Drafts/temp/tmpbshce7ez.wav')\n",
    "audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "mel = whisper.log_mel_spectrogram(audio, n_mels=128).to(model.device)\n",
    "\n",
    "# decode the audio\n",
    "options = whisper.DecodingOptions(language='ru')\n",
    "result = whisper.decode(model, mel, options)\n",
    "\n",
    "# make log-Mel spectrogram and move to the same device as the model\n",
    "result.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformers Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/huggingface/transformers/pull/28556/files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"openai/whisper-large-v3-turbo\"\n",
    "\n",
    "model = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, use_safetensors=True\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "# Enable static cache and compile the forward pass\n",
    "model.generation_config.max_new_tokens = 256\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "generate_kwargs = {\n",
    "    \"condition_on_prev_tokens\": True,\n",
    "    \"temperature\": (0.0, 0.2, 0.4),\n",
    "    \"logprob_threshold\": -0.4,\n",
    "    \"no_speech_threshold\": 0.05,\n",
    "    \"return_timestamps\": \"word\",\n",
    "    #\"task\": \"transcribe\",\n",
    "    \"language\": \"russian\",\n",
    "    #\"initial_prompt\": \"ФСК\"  # https://github.com/huggingface/transformers/issues/27317\n",
    "    \n",
    "}\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    chunk_length_s=30,  # When no is passed - sliding window\n",
    "    batch_size=32,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    "    generate_kwargs=generate_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipe('c:/Users/Alex/whisper_asr_implementation/Drafts/temp/tmpxf4eqn1b.wav', return_timestamps=True)\n",
    "\n",
    "for chunk in result[\"chunks\"]:\n",
    "    print(str(chunk[\"timestamp\"]) + '  ' + chunk['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attempt 31-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of audio file paths (up to 10 files)\n",
    "audio_file_paths = [\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/in-7035555-9587853839-20240802-155950-1722603590.21580.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/out-3036641-3133-20240802-135335-1722596015.21347.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3101-000047e6-2024-08-02-15-28-09.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3213-000044b5-2024-08-02-09-34-26.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3223-0000454f-2024-08-02-10-35-26.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-3353-000048a9-2024-08-02-18-28-28.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5101-000046c7-2024-08-02-13-00-10.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5101-0000459d-2024-08-02-11-16-40.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5101-00004669-2024-08-02-12-27-31.wav\",\n",
    "    \"E:/Записи/ФСК СЗ/incom/08/02/PJSIP-5102-000045ea-2024-08-02-11-40-30.wav\"\n",
    "]\n",
    "\n",
    "'''audio_file_paths = [\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13143_17303__2023_01_31__11_05_42_100.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13301_17384__2023_02_01__17_43_03_327.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13276_17360__2023_02_01__10_11_14_457.mp3\",\n",
    "    \"E:/Записи/BorAvto/ОП/mix_13170_13171__2023_02_01__17_32_20_210.mp3\"\n",
    "]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import librosa\n",
    "\n",
    "# Load the Whisper model\n",
    "model = whisper.load_model(\"turbo\")\n",
    "stereo_path = 'E:/Записи/ФСК/2021062309023419811401pri.wav'\n",
    "# Load the stereo audio file with librosa\n",
    "audio, sr = librosa.load(stereo_path, sr=8000, mono=False)\n",
    "\n",
    "# Ensure the audio has two channels\n",
    "if audio.shape[0] != 2:\n",
    "    raise ValueError(\"Audio file does not have two channels.\")\n",
    "\n",
    "# Separate the left and right channels\n",
    "audio_left = audio[0]\n",
    "audio_right = audio[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the left channel\n",
    "#audio_left = whisper.pad_or_trim(audio_left)\n",
    "\n",
    "# Transcribe the left channel\n",
    "result_left = model.transcribe(\n",
    "    audio_left,\n",
    "    verbose=True,\n",
    "    language='ru'\n",
    ")\n",
    "\n",
    "#print(\"Left Channel Transcription:\")\n",
    "#print(result_left)\n",
    "\n",
    "'''# Process the right channel\n",
    "audio_right = whisper.pad_or_trim(audio_right)\n",
    "mel_right = whisper.log_mel_spectrogram(audio_right, n_mels=128).to(model.device)\n",
    "\n",
    "# Transcribe the right channel using the same options\n",
    "result_right = whisper.decode(model, mel_right, options)\n",
    "print(\"Right Channel Transcription:\")'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VAD approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import librosa\n",
    "import numpy as np\n",
    "import webrtcvad\n",
    "import collections\n",
    "\n",
    "# Step 1: Load and Resample the Audio File\n",
    "audio_path = 'E:/Записи/ФСК/2021062309023419811401pri.wav'\n",
    "audio_data, sr = librosa.load(audio_path, sr=8000, mono=False)  # Keep stereo channels\n",
    "\n",
    "# Resample to 16 kHz\n",
    "audio_data_16k = librosa.resample(audio_data, orig_sr=sr, target_sr=16000)\n",
    "\n",
    "# Step 2: Split into Left and Right Channels\n",
    "left_channel = audio_data_16k[0, :]\n",
    "right_channel = audio_data_16k[1, :]\n",
    "\n",
    "channels = [left_channel, right_channel]\n",
    "\n",
    "# Load the Whisper Model\n",
    "model = whisper.load_model(\"turbo\")\n",
    "\n",
    "# Step 3: Define VAD Functions\n",
    "vad = webrtcvad.Vad(2)  # Aggressiveness mode (0-3)\n",
    "\n",
    "def frame_generator(frame_duration_ms, audio, sample_rate):\n",
    "    frame_length = int(sample_rate * frame_duration_ms / 1000)\n",
    "    num_frames = len(audio) // frame_length\n",
    "    for i in range(num_frames):\n",
    "        yield audio[i * frame_length:(i + 1) * frame_length]\n",
    "\n",
    "def vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, audio):\n",
    "    frames = list(frame_generator(frame_duration_ms, audio, sample_rate))\n",
    "    num_padding_frames = int(padding_duration_ms / frame_duration_ms)\n",
    "    ring_buffer = collections.deque(maxlen=num_padding_frames)\n",
    "    triggered = False\n",
    "    voiced_frames = []\n",
    "    segments = []\n",
    "\n",
    "    for frame in frames:\n",
    "        # Convert to 16-bit PCM\n",
    "        pcm_frame = (frame * 32767).astype(np.int16).tobytes()\n",
    "        is_speech = vad.is_speech(pcm_frame, sample_rate)\n",
    "\n",
    "        if not triggered:\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_voiced = len([f for f, speech in ring_buffer if speech])\n",
    "            if num_voiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = True\n",
    "                voiced_frames.extend([f for f, s in ring_buffer])\n",
    "                ring_buffer.clear()\n",
    "        else:\n",
    "            voiced_frames.append(frame)\n",
    "            ring_buffer.append((frame, is_speech))\n",
    "            num_unvoiced = len([f for f, speech in ring_buffer if not speech])\n",
    "            if num_unvoiced > 0.9 * ring_buffer.maxlen:\n",
    "                triggered = False\n",
    "                segments.append(np.concatenate(voiced_frames))\n",
    "                ring_buffer.clear()\n",
    "                voiced_frames = []\n",
    "    if voiced_frames:\n",
    "        segments.append(np.concatenate(voiced_frames))\n",
    "    return segments\n",
    "\n",
    "# Step 4: Transcribe Each Channel\n",
    "sample_rate = 16000\n",
    "frame_duration_ms = 30\n",
    "padding_duration_ms = 300\n",
    "\n",
    "for idx, ch in enumerate(channels):\n",
    "    # Apply VAD\n",
    "    speech_segments = vad_collector(sample_rate, frame_duration_ms, padding_duration_ms, vad, ch)\n",
    "    print(f\"Processing Channel {idx + 1}\")\n",
    "    for i, segment in enumerate(speech_segments):\n",
    "        # Transcribe with Whisper\n",
    "        result = model.transcribe(segment, language='ru', fp16=False)\n",
    "        print(f\"Segment {i + 1}: {result['text']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "import os\n",
    "\n",
    "# Diarization Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-3.1\",\n",
    "    use_auth_token='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'  # Replace with your Hugging Face token\n",
    ")\n",
    "pipeline.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [\"E:/Записи/Мигкредит/1/1_Ивченко Д.А_2018-12-10_15-50-35_6136_89055400861_4H7P4LS4QL76B4U1JRH8R0HRAG000939_pcmu.wav\",\n",
    "           \"E:/Записи/Мигкредит/1/9_Стриж А_2018-12-10_09-23-21_6127_89033605019_IBA75L9EK10JJ452OB2KJ0H51K007DO2_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2016-11-22_06-30-11_6136_89518759355_6IMC8TIPUP6BD8RC4L2T32JC6O07SK0M_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2016-11-22_06-32-02_6136_89518759355_6IMC8TIPUP6BD8RC4L2T32JC6O07SKAU_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2017-12-29_07-52-31_6130_89303431192_Садоев К.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-03-18_15-07-01_6132_89507086469_Перелыгин И.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-03-23_05-35-26_6135_89025322333_38NDLA8KCD09R2FR3R9CO3JCT4017CD2_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-03-23_05-37-29_6135_89025322333_38NDLA8KCD09R2FR3R9CO3JCT4017CE9_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-03-26_11-09-32_6171_89610426801_Гспоян М.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-03-29_10-00-38_6001_89535554036_Автаев А.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-06-06_12-52-10_6134_88462604792_3RKH6IPB751TR09NAMG5QSSGJK01CHLB_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-06-12_04-01-07_6001_89824570468_3RKH6IPB751TR09NAMG5QSSGJK01PAC9_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-06-18_10-00-20_6140_89677413899_R4P7NOLATT55TD0ANNFK8URBGG00R4AM_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-06-18_13-00-21_6129_89123448698_R4P7NOLATT55TD0ANNFK8URBGG00RJE2_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-07-04_09-14-52_Resources_89655729177_BJSQGAOFE15KN5QPPG58M763MC00KMBI_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-08-14_08-11-05_Resources_89103996696_9L22UTJ9DH4TT09F3KID43KHUS00L1LC_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-09-20_14-00-24_6133_89993680214_FTHN9PABGL6PN0RKA92QRCNI5S00V767_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-09-20_14-07-23_6133_89993680214_FTHN9PABGL6PN0RKA92QRCNI5S00V81R_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-10-17_06-27-29_4992679575_4997023679_38CBN0BE1569T2FAUHMUAT12TC00CV1V_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2018-10-20_14-17-38_6130_89260446126_38CBN0BE1569T2FAUHMUAT12TC00JKQO_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2022-02-23_05-15-49_6106_89134343721_0J8UE9S7N91VL6BMQFUNONT6VS03FMR4_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2022-04-08_08-35-58_6105_89113208278_DCM56DJNV90PR2IQHNAON84VMK00RUAA_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2022-04-11_07-29-22_6105_89113208278_DCM56DJNV90PR2IQHNAON84VMK0128T2_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2022-11-16_12-40-48_Resources_89204089388_1IE7MJESO941555IRFPUOP8EJO0DO534_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2023-01-02_12-31-54_6104_89652214529_1IE7MJESO941555IRFPUOP8EJO0I5MCA_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2023-01-02_12-53-54_6104_89103617383_1IE7MJESO941555IRFPUOP8EJO0I5MD1_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2023-01-02_13-06-43_9111471194_4997023679_1IE7MJESO941555IRFPUOP8EJO0I5MDD_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2023-02-27_05-35-48_Resources_89035610477_TRG4D987PP3P3AE4SA59SAUVVK083UAU_pcmu.wav\",\n",
    "\"E:/Записи/Мигкредит/1/2023-03-07_04-14-56_Resources_89122646096_TRG4D987PP3P3AE4SA59SAUVVK092JNT_pcmu.wav\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline(dataset[i], num_speakers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = pipeline(dataset[i], num_speakers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/transcribe_audio_bulk\"\n",
    "\n",
    "file_name = '3d56f4f9-89cd-4b28-8512-c048edfeddf7.MOV'\n",
    "file_path = f'C:\\\\Users\\\\Alex\\\\golos-hub-back\\\\uploads\\\\2025\\\\02\\\\04\\\\3d56f4f9-89cd-4b28-8512-c048edfeddf7.MOV'\n",
    "\n",
    "payload = {}\n",
    "files=[\n",
    "  ('files',(file_name,open(file_path,'rb'),'audio/wav'))\n",
    "]\n",
    "headers = {}\n",
    "\n",
    "transcription = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "\n",
    "\n",
    "url = \"http://127.0.0.1:8001/diarize_audio_bulk\"\n",
    "\n",
    "payload = {'num_speakers': '2'}\n",
    "files=[\n",
    "  ('files',(file_name,open(file_path,'rb'),'audio/wav'))\n",
    "]\n",
    "headers = {}\n",
    "\n",
    "segments = requests.request(\"POST\", url, headers=headers, data=payload, files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = segments.json()\n",
    "transcription = transcription.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_transcription_with_diarization(transcription, diarization, overlap_threshold=0.1):\n",
    "    \"\"\"\n",
    "    Aligns transcription words with diarization segments, ensuring each word is\n",
    "    aligned with all segments it significantly overlaps with.\n",
    "    \"\"\"\n",
    "    # Flatten the word list from the transcription data\n",
    "    words = []\n",
    "    for speaker, segments in transcription.items():\n",
    "        for segment in segments:\n",
    "            words.extend(segment['words'])\n",
    "    \n",
    "    aligned_words = []\n",
    "    \n",
    "    # Loop over each word to align it with overlapping diarization segments\n",
    "    for word in words:\n",
    "        word_start = word['start']\n",
    "        word_end = word['end']\n",
    "        word_duration = word_end - word_start\n",
    "        word_text = word['word']\n",
    "    \n",
    "        # Keep track of overlaps with each speaker\n",
    "        overlaps = []\n",
    "    \n",
    "        # Compare the word against all diarization segments\n",
    "        for diarization_segment in diarization:\n",
    "            segment_start = diarization_segment['start']\n",
    "            segment_end = diarization_segment['end']\n",
    "            segment_speaker = diarization_segment['speaker']\n",
    "    \n",
    "            # Calculate overlap\n",
    "            overlap_start = max(word_start, segment_start)\n",
    "            overlap_end = min(word_end, segment_end)\n",
    "            overlap_duration = max(0, overlap_end - overlap_start)\n",
    "    \n",
    "            # Calculate overlap percentage\n",
    "            overlap_percentage = overlap_duration / word_duration if word_duration > 0 else 0\n",
    "    \n",
    "            # Assign word to speaker if overlap is significant\n",
    "            if overlap_percentage >= overlap_threshold:\n",
    "                overlaps.append(segment_speaker)\n",
    "    \n",
    "        # Append aligned words for all overlapping speakers\n",
    "        for speaker in overlaps:\n",
    "            aligned_word = {\n",
    "                'word': word_text,\n",
    "                'start': word_start,\n",
    "                'end': word_end,\n",
    "                'speaker': speaker\n",
    "            }\n",
    "            aligned_words.append(aligned_word)\n",
    "    \n",
    "    return aligned_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = align_transcription_with_diarization(\n",
    "transcription[file_name],\n",
    "segments[file_name]['diarization'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_speech_bubbles(transcription, pause_threshold=0.5, max_duration=5.0):\n",
    "    speech_bubbles = []\n",
    "    speaker_bubbles = {}  # Holds the current bubble for each speaker\n",
    "    last_end_times = {}   # Tracks the last end time for each speaker\n",
    "\n",
    "    # Ensure transcription is sorted by start time\n",
    "    transcription.sort(key=lambda x: x['start'])\n",
    "\n",
    "    for word_data in transcription:\n",
    "        word = word_data['word']\n",
    "        start_time = word_data['start']\n",
    "        end_time = word_data['end']\n",
    "        speaker = word_data['speaker']\n",
    "\n",
    "        # Initialize the current bubble for the speaker if not already present\n",
    "        if speaker not in speaker_bubbles:\n",
    "            speaker_bubbles[speaker] = {\"speaker\": speaker, \"start\": None, \"end\": None, \"text\": \"\", \"overlap\": False}\n",
    "            last_end_times[speaker] = None\n",
    "\n",
    "        current_bubble = speaker_bubbles[speaker]\n",
    "        last_end_time = last_end_times[speaker]\n",
    "\n",
    "        # If the current bubble is empty, initialize it with the current word\n",
    "        if current_bubble[\"start\"] is None:\n",
    "            current_bubble[\"start\"] = start_time\n",
    "            current_bubble[\"end\"] = end_time\n",
    "            current_bubble[\"text\"] = word\n",
    "        else:\n",
    "            # Check if we need to start a new bubble\n",
    "            has_long_pause = last_end_time and (start_time - last_end_time > pause_threshold)\n",
    "            exceeds_max_duration = (end_time - current_bubble[\"start\"]) > max_duration\n",
    "\n",
    "            if has_long_pause or exceeds_max_duration:\n",
    "                # Finalize the current bubble and start a new one\n",
    "                speech_bubbles.append(current_bubble)\n",
    "                speaker_bubbles[speaker] = {\n",
    "                    \"speaker\": speaker,\n",
    "                    \"start\": start_time,\n",
    "                    \"end\": end_time,\n",
    "                    \"text\": word,\n",
    "                    \"overlap\": False\n",
    "                }\n",
    "                current_bubble = speaker_bubbles[speaker]\n",
    "            else:\n",
    "                # Continue the current bubble\n",
    "                current_bubble[\"text\"] += \" \" + word\n",
    "                current_bubble[\"end\"] = end_time\n",
    "\n",
    "        # Update the last end time for the speaker\n",
    "        last_end_times[speaker] = end_time\n",
    "\n",
    "    # Append any remaining bubbles\n",
    "    for bubble in speaker_bubbles.values():\n",
    "        if bubble[\"start\"] is not None:\n",
    "            speech_bubbles.append(bubble)\n",
    "\n",
    "    # Now, sort the bubbles by start time\n",
    "    speech_bubbles.sort(key=lambda x: x['start'])\n",
    "\n",
    "    # Detect overlaps between bubbles of different speakers and set 'overlap': True\n",
    "    for i in range(len(speech_bubbles)):\n",
    "        bubble_i = speech_bubbles[i]\n",
    "        for j in range(i + 1, len(speech_bubbles)):\n",
    "            bubble_j = speech_bubbles[j]\n",
    "            # Stop checking if the next bubble starts after the current bubble ends\n",
    "            if bubble_j['start'] > bubble_i['end']:\n",
    "                break\n",
    "            # Check if bubbles are from different speakers and overlap\n",
    "            if bubble_i['speaker'] != bubble_j['speaker']:\n",
    "                # Check for overlap\n",
    "                start_i, end_i = bubble_i['start'], bubble_i['end']\n",
    "                start_j, end_j = bubble_j['start'], bubble_j['end']\n",
    "                # Overlap exists if start_i < end_j and start_j < end_i\n",
    "                if start_i < end_j and start_j < end_i:\n",
    "                    # Set 'overlap': True in both bubbles\n",
    "                    bubble_i['overlap'] = True\n",
    "                    bubble_j['overlap'] = True\n",
    "\n",
    "    return speech_bubbles\n",
    "\n",
    "def generate_html_with_media_player(speech_bubbles, audio_file_url, output_filename=\"transcription_with_player.html\"):\n",
    "    # Define the HTML structure with Plyr.js for the media player\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Speech Bubbles with Media Player</title>\n",
    "        <link rel=\"stylesheet\" href=\"https://cdn.plyr.io/3.7.8/plyr.css\" />\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: Arial, sans-serif;\n",
    "                background-color: #f4f4f9;\n",
    "                color: #333;\n",
    "                padding: 20px;\n",
    "                margin: 0;\n",
    "                display: flex;\n",
    "                flex-direction: column;\n",
    "                align-items:center;\n",
    "            }}\n",
    "            .sticky-player {{\n",
    "                position: fixed;\n",
    "                top: 10px;\n",
    "                left: 50%;\n",
    "                transform: translateX(-50%);\n",
    "                z-index: 1000;\n",
    "                width: 90%;\n",
    "                max-width: 600px;\n",
    "                background-color: white;\n",
    "                border: 1px solid #ccc;\n",
    "                border-radius: 10px;\n",
    "                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "                padding: 10px;\n",
    "            }}\n",
    "            .bubble-container {{\n",
    "                display: flex;\n",
    "                flex-direction: column;\n",
    "                gap: 10px;\n",
    "                margin-top: 120px; /* To avoid overlapping with the fixed player */\n",
    "            }}\n",
    "            .bubble {{\n",
    "                border-radius: 10px;\n",
    "                padding: 15px;\n",
    "                max-width: 70%;\n",
    "                word-wrap: break-word;\n",
    "            }}\n",
    "            .bubble.speaker-0 {{\n",
    "                background-color: #d1e7ff;\n",
    "                color: #0a58ca;\n",
    "                align-self: flex-start;\n",
    "            }}\n",
    "            .bubble.speaker-1 {{\n",
    "                background-color: #ffe0e0;\n",
    "                color: #c92a2a;\n",
    "                align-self: flex-end;\n",
    "            }}\n",
    "            .timestamp {{\n",
    "                font-size: 0.85em;\n",
    "                color: #555;\n",
    "                margin-top: 5px;\n",
    "                text-align: right;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"sticky-player\">\n",
    "            <audio id=\"player\" controls>\n",
    "                <source src=\"{audio_file_url}\" type=\"audio/mpeg\">\n",
    "                Your browser does not support the audio element.\n",
    "            </audio>\n",
    "        </div>\n",
    "        <div class=\"bubble-container\">\n",
    "    \"\"\"\n",
    "\n",
    "    # Add bubbles for each speech segment\n",
    "    for bubble in speech_bubbles:\n",
    "        speaker_class = \"speaker-0\" if bubble[\"speaker\"] == \"SPEAKER_00\" else \"speaker-1\"\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"bubble {speaker_class}\">\n",
    "            <div class=\"text\">{bubble[\"text\"]}</div>\n",
    "            <div class=\"timestamp\">[{bubble[\"start\"]:.2f} - {bubble[\"end\"]:.2f}]</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    # Close the HTML structure\n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "        <script src=\"https://cdn.plyr.io/3.7.8/plyr.polyfilled.js\"></script>\n",
    "        <script>\n",
    "            const player = new Plyr('#player', {\n",
    "                controls: ['play', 'progress', 'current-time', 'duration', 'mute', 'volume']\n",
    "            });\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    # Write to an HTML file\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML file with media player has been generated: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles = create_speech_bubbles(test)\n",
    "\n",
    "generate_html_with_media_player(bubbles, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom overlapping approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_speech_bubbles_t(transcription, pause_threshold=0.5, max_duration=5.0):\n",
    "    speech_bubbles = []\n",
    "    speaker_bubbles = {}  # Holds the current bubble for each speaker\n",
    "    last_end_times = {}   # Tracks the last end time for each speaker\n",
    "\n",
    "    # Ensure transcription is sorted by start time\n",
    "    transcription.sort(key=lambda x: x['start'])\n",
    "\n",
    "    for word_data in transcription:\n",
    "        word = word_data['word']\n",
    "        start_time = word_data['start']\n",
    "        end_time = word_data['end']\n",
    "        speaker = word_data['speaker']\n",
    "\n",
    "        # Initialize the current bubble for the speaker if not already present\n",
    "        if speaker not in speaker_bubbles:\n",
    "            speaker_bubbles[speaker] = {\"speaker\": speaker, \"start\": None, \"end\": None, \"text\": \"\", \"overlap\": \"\"}\n",
    "            last_end_times[speaker] = None\n",
    "\n",
    "        current_bubble = speaker_bubbles[speaker]\n",
    "        last_end_time = last_end_times[speaker]\n",
    "\n",
    "        # If the current bubble is empty, initialize it with the current word\n",
    "        if current_bubble[\"start\"] is None:\n",
    "            current_bubble[\"start\"] = start_time\n",
    "            current_bubble[\"end\"] = end_time\n",
    "            current_bubble[\"text\"] = word\n",
    "        else:\n",
    "            # Check if we need to start a new bubble\n",
    "            has_long_pause = last_end_time and (start_time - last_end_time > pause_threshold)\n",
    "            exceeds_max_duration = (end_time - current_bubble[\"start\"]) > max_duration\n",
    "\n",
    "            if has_long_pause or exceeds_max_duration:\n",
    "                # Finalize the current bubble and start a new one\n",
    "                speech_bubbles.append(current_bubble)\n",
    "                speaker_bubbles[speaker] = {\n",
    "                    \"speaker\": speaker,\n",
    "                    \"start\": start_time,\n",
    "                    \"end\": end_time,\n",
    "                    \"text\": word,\n",
    "                    \"overlap\": \"\"\n",
    "                }\n",
    "                current_bubble = speaker_bubbles[speaker]\n",
    "            else:\n",
    "                # Continue the current bubble\n",
    "                current_bubble[\"text\"] += \"\" + word\n",
    "                current_bubble[\"end\"] = end_time\n",
    "\n",
    "        # Update the last end time for the speaker\n",
    "        last_end_times[speaker] = end_time\n",
    "\n",
    "    # Append any remaining bubbles\n",
    "    for bubble in speaker_bubbles.values():\n",
    "        if bubble[\"start\"] is not None:\n",
    "            speech_bubbles.append(bubble)\n",
    "\n",
    "    # Sort the bubbles by start time\n",
    "    speech_bubbles.sort(key=lambda x: x['start'])\n",
    "\n",
    "    # Detect overlaps between bubbles of different speakers and capture exact sequences\n",
    "    for i in range(len(speech_bubbles)):\n",
    "        bubble_i = speech_bubbles[i]\n",
    "        for j in range(i + 1, len(speech_bubbles)):\n",
    "            bubble_j = speech_bubbles[j]\n",
    "            # Stop checking if the next bubble starts after the current bubble ends\n",
    "            if bubble_j['start'] > bubble_i['end']:\n",
    "                break\n",
    "            # Check if bubbles are from different speakers and overlap\n",
    "            if bubble_i['speaker'] != bubble_j['speaker']:\n",
    "                # Check for overlap\n",
    "                start_i, end_i = bubble_i['start'], bubble_i['end']\n",
    "                start_j, end_j = bubble_j['start'], bubble_j['end']\n",
    "                if start_i < end_j and start_j < end_i:\n",
    "                    # Identify exact overlapping sequences\n",
    "                    words_i = bubble_i['text'].split()\n",
    "                    words_j = bubble_j['text'].split()\n",
    "                    overlap_sequence = []\n",
    "\n",
    "                    # Compare sequences of words\n",
    "                    for idx_i, word_i in enumerate(words_i):\n",
    "                        for idx_j, word_j in enumerate(words_j):\n",
    "                            if word_i == word_j:\n",
    "                                temp_sequence = []\n",
    "                                k = 0\n",
    "                                # Check for a sequence match\n",
    "                                while (\n",
    "                                    idx_i + k < len(words_i)\n",
    "                                    and idx_j + k < len(words_j)\n",
    "                                    and words_i[idx_i + k] == words_j[idx_j + k]\n",
    "                                ):\n",
    "                                    temp_sequence.append(words_i[idx_i + k])\n",
    "                                    k += 1\n",
    "                                if len(temp_sequence) > len(overlap_sequence):\n",
    "                                    overlap_sequence = temp_sequence\n",
    "\n",
    "                    if overlap_sequence:\n",
    "                        overlap_text = \" \".join(overlap_sequence)\n",
    "                        bubble_i['overlap'] = overlap_text\n",
    "                        bubble_j['overlap'] = overlap_text\n",
    "\n",
    "    return speech_bubbles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_html_with_media_player_t(speech_bubbles, audio_file_url, output_filename=\"transcription_with_player.html\"):\n",
    "    html_content = f\"\"\"\n",
    "    <!DOCTYPE html>\n",
    "    <html lang=\"en\">\n",
    "    <head>\n",
    "        <meta charset=\"UTF-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
    "        <title>Speech Bubbles with Media Player</title>\n",
    "        <link rel=\"stylesheet\" href=\"https://cdn.plyr.io/3.7.8/plyr.css\" />\n",
    "        <style>\n",
    "            body {{\n",
    "                font-family: Arial, sans-serif;\n",
    "                background-color: #f4f4f9;\n",
    "                color: #333;\n",
    "                padding: 20px;\n",
    "                margin: 0;\n",
    "                display: flex;\n",
    "                flex-direction: column;\n",
    "                align-items:center;\n",
    "            }}\n",
    "            .sticky-player {{\n",
    "                position: fixed;\n",
    "                top: 10px;\n",
    "                left: 50%;\n",
    "                transform: translateX(-50%);\n",
    "                z-index: 1000;\n",
    "                width: 90%;\n",
    "                max-width: 600px;\n",
    "                background-color: white;\n",
    "                border: 1px solid #ccc;\n",
    "                border-radius: 10px;\n",
    "                box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);\n",
    "                padding: 10px;\n",
    "            }}\n",
    "            .bubble-container {{\n",
    "                display: flex;\n",
    "                flex-direction: column;\n",
    "                gap: 10px;\n",
    "                margin-top: 120px;\n",
    "            }}\n",
    "            .bubble {{\n",
    "                border-radius: 10px;\n",
    "                padding: 15px;\n",
    "                max-width: 70%;\n",
    "                word-wrap: break-word;\n",
    "            }}\n",
    "            .bubble.speaker-0 {{\n",
    "                background-color: #d1e7ff;\n",
    "                color: #0a58ca;\n",
    "                align-self: flex-start;\n",
    "            }}\n",
    "            .bubble.speaker-1 {{\n",
    "                background-color: #ffe0e0;\n",
    "                color: #c92a2a;\n",
    "                align-self: flex-end;\n",
    "            }}\n",
    "            .overlap-word {{\n",
    "                font-weight: bold;\n",
    "            }}\n",
    "            .timestamp {{\n",
    "                font-size: 0.85em;\n",
    "                color: #555;\n",
    "                margin-top: 5px;\n",
    "                text-align: right;\n",
    "            }}\n",
    "        </style>\n",
    "    </head>\n",
    "    <body>\n",
    "        <div class=\"sticky-player\">\n",
    "            <audio id=\"player\" controls>\n",
    "                <source src=\"{audio_file_url}\" type=\"audio/mpeg\">\n",
    "                Your browser does not support the audio element.\n",
    "            </audio>\n",
    "        </div>\n",
    "        <div class=\"bubble-container\">\n",
    "    \"\"\"\n",
    "\n",
    "    # Add bubbles for each speech segment\n",
    "    for bubble in speech_bubbles:\n",
    "        speaker_class = \"speaker-0\" if bubble[\"speaker\"] == \"SPEAKER_00\" else \"speaker-1\"\n",
    "        text = bubble[\"text\"]\n",
    "        if bubble[\"overlap\"]:\n",
    "            # Highlight overlapping words\n",
    "            overlap_words = bubble[\"overlap\"].split()\n",
    "            for word in overlap_words:\n",
    "                text = text.replace(word, f\"<span class='overlap-word'>{word}</span>\")\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"bubble {speaker_class}\">\n",
    "            <div class=\"text\">{text}</div>\n",
    "            <div class=\"timestamp\">[{bubble[\"start\"]:.2f} - {bubble[\"end\"]:.2f}]</div>\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "    # Close the HTML structure\n",
    "    html_content += \"\"\"\n",
    "        </div>\n",
    "        <script src=\"https://cdn.plyr.io/3.7.8/plyr.polyfilled.js\"></script>\n",
    "        <script>\n",
    "            const player = new Plyr('#player', {\n",
    "                controls: ['play', 'progress', 'current-time', 'duration', 'mute', 'volume']\n",
    "            });\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    \"\"\"\n",
    "\n",
    "    with open(output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)\n",
    "\n",
    "    print(f\"HTML file with media player has been generated: {output_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles = create_speech_bubbles_t(test)\n",
    "\n",
    "generate_html_with_media_player_t(bubbles, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bubbles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"http://127.0.0.1:8000/transcribe_audio_bulk\"\n",
    "\n",
    "file_name = '3d56f4f9-89cd-4b28-8512-c048edfeddf7.MOV'\n",
    "#'2023-09-15_15-35-23_Resources_89688627131_TRG4D987PP3P3AE4SA59SAUVVK14OK43_pcmu.wav'\n",
    "file_path = f'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/3d56f4f9-89cd-4b28-8512-c048edfeddf7.MOV'\n",
    "mp3 = f'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/3d56f4f9-89cd-4b28-8512-c048edfeddf7.MOV{file_name[:-4]}'+'.wav'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_mono_wav(input_path: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Converts an audio/video file to a mono WAV file with 16kHz sample rate using FFmpeg.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not output_path.lower().endswith('.wav'):\n",
    "            raise ValueError(\"Output file must have a .wav extension\")\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",                # Overwrite without prompt.\n",
    "            \"-i\", input_path,    # Input file.\n",
    "            \"-ac\", \"1\",          # Force mono.\n",
    "            \"-acodec\", \"pcm_s16le\",  # WAV encoding.\n",
    "            \"-ar\", \"16000\",      # Sampling rate: 16 kHz.\n",
    "            output_path\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        if not os.path.exists(output_path):\n",
    "            raise RuntimeError(\"Conversion failed; output file not created.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error in convert_to_mono_wav:\", e)\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "convert_to_mono_wav(file_path, mp3)\n",
    "file_path = mp3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = {}\n",
    "files=[\n",
    "  ('files',(file_name,open(file_path,'rb'),'audio/wav'))\n",
    "]\n",
    "headers = {}\n",
    "\n",
    "transcription = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "print('ASR -- OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://127.0.0.1:8001/diarize_audio_bulk\"\n",
    "payload = {'num_speakers': None}\n",
    "files=[\n",
    "  ('files',(file_name,open(file_path,'rb'),'audio/wav'))\n",
    "]\n",
    "headers = {}\n",
    "segments = requests.request(\"POST\", url, headers=headers, data=payload, files=files)\n",
    "print('DIARIZATION -- OK')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments2 = segments.json()[file_name]['diarization']\n",
    "transcription2 = transcription.json()[file_name]\n",
    "\n",
    "url = \"http://127.0.0.1:8002/process-transcription\"\n",
    "\n",
    "process_payload = {\n",
    "    \"transcription\": transcription2,\n",
    "    \"diarization\": segments2\n",
    "}\n",
    "\n",
    "bubbles = requests.request(\"POST\", url, json=process_payload)\n",
    "print('ALLIGNMENT -- OK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://127.0.0.1:8002/generate-html\"\n",
    "\n",
    "bubbles_input2 = bubbles.json()['speech_bubbles']\n",
    "query_params = {\"audio_file_url\": file_path}\n",
    "\n",
    "\n",
    "html = requests.request(\"POST\", url, params=query_params, json=bubbles_input2)\n",
    "print('HTML PREVIEW -- OK')\n",
    "\n",
    "html_content = html.json()['html']\n",
    "\n",
    "with open('./test_preview_new.html', \"w\", encoding=\"utf-8\") as file:\n",
    "        file.write(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQLite Queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import traceback\n",
    "\n",
    "def convert_to_mono_wav(input_path: str, output_path: str) -> None:\n",
    "    try:\n",
    "        \"\"\"\n",
    "        Converts an audio/video file to a WAV file using FFmpeg.\n",
    "        \n",
    "        :param input_path:  Path to the input file (e.g., 'song.mp3', 'video.mp4', 'recording.ogg', etc.).\n",
    "        :param output_path: Desired path for the output WAV (e.g., 'output.wav').\n",
    "        \"\"\"\n",
    "        # Make sure output_path ends with .wav\n",
    "        if not output_path.lower().endswith('.wav'):\n",
    "            raise ValueError(\"Output file must have a .wav extension\")\n",
    "\n",
    "        # Build the FFmpeg command\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",                # Overwrite output file without asking\n",
    "            \"-i\", input_path,    # Input file\n",
    "            \"-ac\", \"1\",           # Convert to mono\n",
    "            \"-acodec\", \"pcm_s16le\",  # Set WAV encoding\n",
    "            \"-ar\", \"16000\",      # Sampling rate (common standard: 16 kHz)\n",
    "            output_path\n",
    "        ]\n",
    "        \n",
    "        # Execute the command\n",
    "        subprocess.run(command, check=True)\n",
    "        \n",
    "        if not os.path.exists(output_path):\n",
    "            raise RuntimeError(\"Conversion failed; output file not created.\")\n",
    "    except:\n",
    "        traceback.print_exc()\n",
    "\n",
    "    # Example usage:\n",
    "    # convert_to_wav(\"example.mp4\", \"output.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [19216]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8005 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:55382 - \"GET /job_status/57 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55382 - \"GET /get_transcription/57 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55382 - \"GET /job_status/58 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55382 - \"GET /get_transcription/58 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55382 - \"GET /job_status/59 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55382 - \"GET /job_status/60 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:55382 - \"GET /get_transcription/60 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [19216]\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel, Field\n",
    "import uvicorn\n",
    "import sqlite3\n",
    "import json\n",
    "from typing import Optional, List\n",
    "import datetime\n",
    "\n",
    "# Same Pydantic model definitions and DB code\n",
    "class JobCreate(BaseModel):\n",
    "\n",
    "    source: str = Field(..., description=\"Source of the job (required)\")\n",
    "    files: str = Field(..., description=\"File Path, one only (required)\")\n",
    "    type: Optional[str] = None\n",
    "    diarization: Optional[bool] = None\n",
    "    n_speakers: Optional[int] = None\n",
    "    language: Optional[str] = None\n",
    "    # Optional fields\n",
    "    # source_data: Optional[dict] = None\n",
    "    size: Optional[str] = None\n",
    "    transcription: Optional[dict] = None\n",
    "    transcribed_at: Optional[str] = None\n",
    "    time_taken: Optional[str] = None\n",
    "\n",
    "class JobResponse(BaseModel):\n",
    "    job_id: int\n",
    "    message: str\n",
    "    queue: int\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "DATABASE = \"./asr_queue.db\"\n",
    "\n",
    "@app.get(\"/job_status/{job_id}\")\n",
    "def job_status(job_id: int):\n",
    "    \"\"\"\n",
    "    Fetch the 'status' column from the 'jobs' table\n",
    "    for the given job_id.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        conn = sqlite3.connect(DATABASE)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # Query the job by job_id\n",
    "        cursor.execute(\"SELECT status FROM jobs WHERE job_id = ?\", (job_id,))\n",
    "        row = cursor.fetchone()\n",
    "        \n",
    "        if row is None:\n",
    "            # No job found with the given job_id\n",
    "            raise HTTPException(status_code=404, detail=\"Job not found\")\n",
    "        \n",
    "        status = row[0]  # The 'status' from the row\n",
    "        if status is None:\n",
    "            # If the 'status' is NULL in the database\n",
    "            raise HTTPException(status_code=404, detail=\"No status available for this job\")\n",
    "        \n",
    "        # 2. Get the total number of rows that have \"in queue\" status\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT COUNT(*) \n",
    "            FROM jobs \n",
    "            WHERE status = 'in queue' \n",
    "              AND job_id <= ?\n",
    "        \"\"\", (job_id,))\n",
    "\n",
    "        count_in_queue = cursor.fetchone()\n",
    "        queue_count = count_in_queue[0] if count_in_queue else 0\n",
    "        \n",
    "    except sqlite3.Error as e:\n",
    "        # Database error\n",
    "        raise HTTPException(status_code=500, detail=f\"Database error: {str(e)}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    # Return the status in a JSON object\n",
    "    return {\"status\": status,\n",
    "            \"queue\": queue_count}\n",
    "\n",
    "@app.post(\"/add_job\", response_model=JobResponse)\n",
    "def create_job(job: JobCreate):\n",
    "    # 1. Automatically set 'added_at' (no milliseconds)\n",
    "    added_at_str = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    \n",
    "    # 2. Force 'status' to be \"in queue\"\n",
    "    status_str = \"in queue\"\n",
    "    \n",
    "    # 3. Convert JSON fields to strings if present\n",
    "    settings = {}\n",
    "    settings['format'] = job.type if job.type else 'mono-stereo'\n",
    "    settings['diarization'] = job.diarization if job.diarization else False\n",
    "    settings['num_speakers'] = job.n_speakers if job.n_speakers else False\n",
    "    settings['language'] = job.language if job.language else False\n",
    "    source_data_str = json.dumps(settings)\n",
    "    transcription_str = json.dumps(job.transcription) if job.transcription else None\n",
    "    files_str = json.dumps(job.files, ensure_ascii=False)  # required\n",
    "    \n",
    "    try:\n",
    "        # Connect to the database\n",
    "        conn = sqlite3.connect(DATABASE)\n",
    "        cursor = conn.cursor()\n",
    "        \n",
    "        # 4. Insert into DB\n",
    "        insert_sql = \"\"\"\n",
    "        INSERT INTO jobs (\n",
    "            added_at,\n",
    "            source,\n",
    "            source_data,\n",
    "            files,\n",
    "            size,\n",
    "            status,\n",
    "            transcription,\n",
    "            transcribed_at,\n",
    "            time_taken\n",
    "        )\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        cursor.execute(insert_sql, (\n",
    "            added_at_str,\n",
    "            job.source,\n",
    "            source_data_str,\n",
    "            files_str,\n",
    "            job.size,\n",
    "            status_str,\n",
    "            transcription_str,\n",
    "            job.transcribed_at,\n",
    "            job.time_taken\n",
    "        ))\n",
    "        conn.commit()\n",
    "        \n",
    "        # 5. Get the newly inserted job's ID\n",
    "        job_id = cursor.lastrowid\n",
    "        \n",
    "        # 6. Count how many jobs have 'in queue' AND job_id <= the current job_id\n",
    "        cursor.execute(\"\"\"\n",
    "            SELECT COUNT(*) \n",
    "            FROM jobs \n",
    "            WHERE status = 'in queue' \n",
    "              AND job_id <= ?\n",
    "        \"\"\", (job_id,))\n",
    "        \n",
    "        count_in_queue_row = cursor.fetchone()\n",
    "        queue_count = count_in_queue_row[0] if count_in_queue_row else 0\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"Database error: {str(e)}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "    \n",
    "    # 7. Return success response\n",
    "    return {\n",
    "        \"job_id\": job_id,\n",
    "        \"message\": \"Job added successfully\",\n",
    "        \"queue\": queue_count\n",
    "    }\n",
    "\n",
    "@app.get(\"/get_transcription/{job_id}\")\n",
    "def get_transcription(job_id: int):\n",
    "    \"\"\"\n",
    "    Fetch the 'transcription' column from the 'jobs' table\n",
    "    for the given job_id.\n",
    "    If found, parse and return it as JSON.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(DATABASE)\n",
    "        cursor = conn.cursor()\n",
    "\n",
    "        # 1) Query the job by job_id for the 'transcription' column\n",
    "        cursor.execute(\"SELECT transcription FROM jobs WHERE job_id = ?\", (job_id,))\n",
    "        row = cursor.fetchone()\n",
    "        \n",
    "        if row is None:\n",
    "            raise HTTPException(status_code=404, detail=\"Job not found\")\n",
    "        \n",
    "        transcription_str = row[0]  # The 'transcription' from the row (JSON text)\n",
    "\n",
    "        if not transcription_str:\n",
    "            # If transcription is empty (NULL or empty string),\n",
    "            # it usually means the job hasn't been transcribed yet\n",
    "            raise HTTPException(\n",
    "                status_code=404, \n",
    "                detail=\"No transcription found (job may still be processing)\"\n",
    "            )\n",
    "\n",
    "        # 2) Parse the JSON\n",
    "        try:\n",
    "            transcription_data = json.loads(transcription_str)\n",
    "        except json.JSONDecodeError:\n",
    "            # If the transcription column has invalid JSON\n",
    "            raise HTTPException(status_code=500, detail=\"Corrupted transcription data\")\n",
    "\n",
    "    except sqlite3.Error as e:\n",
    "        # Database error\n",
    "        raise HTTPException(status_code=500, detail=f\"Database error: {str(e)}\")\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    # 3) Return the transcription as JSON\n",
    "    return {\n",
    "        \"transcription\": transcription_data\n",
    "    }\n",
    "\n",
    "# Finally, run Uvicorn server in Jupyter\n",
    "uvicorn.run(app, host=\"127.0.0.1\", port=8005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Job Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import os\n",
    "import tempfile\n",
    "import requests\n",
    "\n",
    "DATABASE = \"./asr_queue.db\"\n",
    "\n",
    "def get_in_queue_jobs(db_path=DATABASE):\n",
    "    \"\"\"Fetch all rows with status='in queue' from the jobs table and parse JSON fields.\"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Define columns in the exact order they appear in your table.\n",
    "    # Adjust if your actual schema/column order differs.\n",
    "    columns = [\n",
    "        \"job_id\",\n",
    "        \"added_at\",\n",
    "        \"source\",\n",
    "        \"source_data\",\n",
    "        \"files\",\n",
    "        \"size\",\n",
    "        \"status\",\n",
    "        \"transcription\",\n",
    "        \"transcribed_at\",\n",
    "        \"time_taken\"\n",
    "    ]\n",
    "    try:\n",
    "        # Fetch all rows where status = 'in queue'\n",
    "        cursor.execute(\"SELECT * FROM jobs WHERE status = 'in queue'\")\n",
    "        rows = cursor.fetchall()\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "    # Convert each row to a dict, parse JSON fields\n",
    "    results = []\n",
    "    for row in rows:\n",
    "        row_dict = dict(zip(columns, row))\n",
    "\n",
    "        # If source_data is a JSON string, parse it into a dict\n",
    "        if row_dict[\"source_data\"]:\n",
    "            try:\n",
    "                row_dict[\"source_data\"] = json.loads(row_dict[\"source_data\"])\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle or log malformed JSON\n",
    "                row_dict[\"source_data\"] = None\n",
    "\n",
    "        # If files is a JSON string (list), parse it into a Python list\n",
    "        if row_dict[\"files\"]:\n",
    "            try:\n",
    "                row_dict[\"files\"] = json.loads(row_dict[\"files\"])\n",
    "            except json.JSONDecodeError:\n",
    "                # Handle or log malformed JSON\n",
    "                row_dict[\"files\"] = []\n",
    "\n",
    "        results.append(row_dict)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_queue_jobs = get_in_queue_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a pack to run the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = in_queue_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_jobs = [job for job in jobs if job.get('source_data', {}).get('format') == 'mono'] + [job for job in jobs if job.get('source_data', {}).get('format') == 'mono-stereo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is what I need\n",
    "# Run the asr endpoint and run diarization simultaneously, where diarization is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job_id': 60,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/03/02/144323ec-025a-4034-a897-10d942666609.wav',\n",
       "  'size': None,\n",
       "  'status': 'in queue',\n",
       "  'transcription': None,\n",
       "  'transcribed_at': None,\n",
       "  'time_taken': None},\n",
       " {'job_id': 57,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono-stereo',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/a352a068-a7d8-476c-af1c-1bd0c9895c2e.MOV',\n",
       "  'size': None,\n",
       "  'status': 'in queue',\n",
       "  'transcription': None,\n",
       "  'transcribed_at': None,\n",
       "  'time_taken': None},\n",
       " {'job_id': 58,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono-stereo',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/6338698c-fb2c-4029-af2d-a7b2f1ee524b.MOV',\n",
       "  'size': None,\n",
       "  'status': 'in queue',\n",
       "  'transcription': None,\n",
       "  'transcribed_at': None,\n",
       "  'time_taken': None},\n",
       " {'job_id': 59,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono-stereo',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/e2796736-feb5-4f98-a7ed-0a80631fc21c.MOV',\n",
       "  'size': None,\n",
       "  'status': 'in queue',\n",
       "  'transcription': None,\n",
       "  'transcribed_at': None,\n",
       "  'time_taken': None}]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1136' coro=<Server.serve() done, defined at c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py:67> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\main.py\", line 579, in run\n",
      "    server.run()\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py\", line 65, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 315, in __wakeup\n",
      "    self.__step()\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py\", line 68, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py\", line 332, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-1164' coro=<Server.serve() done, defined at c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py:67> exception=KeyboardInterrupt()>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\main.py\", line 579, in run\n",
      "    server.run()\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py\", line 65, in run\n",
      "    return asyncio.run(self.serve(sockets=sockets))\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\nest_asyncio.py\", line 30, in run\n",
      "    return loop.run_until_complete(task)\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\nest_asyncio.py\", line 92, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\nest_asyncio.py\", line 133, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 315, in __wakeup\n",
      "    self.__step()\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py\", line 68, in serve\n",
      "    with self.capture_signals():\n",
      "  File \"C:\\Users\\Alex\\AppData\\Local\\Programs\\Python\\Python310\\lib\\contextlib.py\", line 142, in __exit__\n",
      "    next(self.gen)\n",
      "  File \"c:\\Users\\Alex\\whisper_asr_implementation\\venv\\lib\\site-packages\\uvicorn\\server.py\", line 332, in capture_signals\n",
      "    signal.raise_signal(captured_signal)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import datetime\n",
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import traceback\n",
    "from typing import List, Dict, Any, Union\n",
    "import httpx\n",
    "\n",
    "# Global constants\n",
    "MAX_SPEECH_BUBBLE = 15.0\n",
    "PAUSE_THRESHOLD = 1\n",
    "\n",
    "def convert_to_mono_wav(input_path: str, output_path: str) -> None:\n",
    "    \"\"\"\n",
    "    Converts an audio/video file to a mono WAV file with 16kHz sample rate using FFmpeg.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not output_path.lower().endswith('.wav'):\n",
    "            raise ValueError(\"Output file must have a .wav extension\")\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",                # Overwrite without prompt.\n",
    "            \"-i\", input_path,    # Input file.\n",
    "            \"-ac\", \"1\",          # Force mono.\n",
    "            \"-acodec\", \"pcm_s16le\",  # WAV encoding.\n",
    "            \"-ar\", \"16000\",      # Sampling rate: 16 kHz.\n",
    "            output_path\n",
    "        ]\n",
    "        subprocess.run(command, check=True)\n",
    "        if not os.path.exists(output_path):\n",
    "            raise RuntimeError(\"Conversion failed; output file not created.\")\n",
    "    except Exception as e:\n",
    "        print(\"Error in convert_to_mono_wav:\", e)\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "def ensure_list(file_entry: Union[str, List[str]]) -> List[str]:\n",
    "    if isinstance(file_entry, list):\n",
    "        return file_entry\n",
    "    return [file_entry]\n",
    "\n",
    "def create_speech_bubbles_mono(\n",
    "    asr_transcription: Dict[str, List[Dict[str, Any]]],\n",
    "    pause_threshold: float,\n",
    "    max_duration: float\n",
    ") -> List[Dict[str, Any]]:\n",
    "    \"\"\"\n",
    "    Convert a mono (ASR-only) transcription dictionary into a list of speech bubbles\n",
    "    that mimic the diarized output. The ASR transcription is assumed to be a dict\n",
    "    with keys as speaker names (e.g., \"Speaker 0\") and values as a list of segments.\n",
    "    \n",
    "    Each segment should have at least:\n",
    "      - 'start': start time (float)\n",
    "      - 'end': end time (float)\n",
    "      - 'text': the transcribed text for that segment\n",
    "\n",
    "    Consecutive segments for the same speaker are merged if the gap between them\n",
    "    is less than pause_threshold and the overall duration does not exceed max_duration.\n",
    "\n",
    "    The resulting bubble dict has the following keys:\n",
    "      - 'speaker': the speaker identifier\n",
    "      - 'start': the start time of the bubble (first segment's start)\n",
    "      - 'end': the end time of the bubble (last segment's end)\n",
    "      - 'text': concatenated text from all segments in the bubble\n",
    "      - 'overlap': an empty string\n",
    "    \"\"\"\n",
    "    bubbles = []\n",
    "    \n",
    "    for speaker, segments in asr_transcription.items():\n",
    "        # Ensure segments are sorted by start time.\n",
    "        segments.sort(key=lambda seg: seg['start'])\n",
    "        current_bubble = None\n",
    "        \n",
    "        for seg in segments:\n",
    "            seg_text = seg.get('text', '').strip()\n",
    "            if current_bubble is None:\n",
    "                # Start a new bubble.\n",
    "                current_bubble = {\n",
    "                    'speaker': speaker,\n",
    "                    'start': seg['start'],\n",
    "                    'end': seg['end'],\n",
    "                    'text': seg_text,\n",
    "                    'overlap': \"\"\n",
    "                }\n",
    "            else:\n",
    "                gap = seg['start'] - current_bubble['end']\n",
    "                duration = seg['end'] - current_bubble['start']\n",
    "                # If the gap is too large or adding the segment would exceed max_duration,\n",
    "                # finalize the current bubble and start a new one.\n",
    "                if gap > pause_threshold or duration > max_duration:\n",
    "                    bubbles.append(current_bubble)\n",
    "                    current_bubble = {\n",
    "                        'speaker': speaker,\n",
    "                        'start': seg['start'],\n",
    "                        'end': seg['end'],\n",
    "                        'text': seg_text,\n",
    "                        'overlap': \"\"\n",
    "                    }\n",
    "                else:\n",
    "                    # Otherwise, merge this segment into the current bubble.\n",
    "                    current_bubble['end'] = seg['end']\n",
    "                    current_bubble['text'] += \" \" + seg_text\n",
    "        \n",
    "        if current_bubble is not None:\n",
    "            bubbles.append(current_bubble)\n",
    "    \n",
    "    # Sort all bubbles by start time.\n",
    "    bubbles.sort(key=lambda bubble: bubble['start'])\n",
    "    return bubbles\n",
    "\n",
    "# Service Settings\n",
    "ASR_TIMEOUT = 300.0\n",
    "DIAR_TIMEOUT = 60.0\n",
    "ASR_URL = \"http://127.0.0.1:8000/transcribe_audio_local\"\n",
    "DIAR_URL = \"http://127.0.0.1:8001/diarize_audio_bulk_local\"\n",
    "PROCESS_URL = \"http://127.0.0.1:8002/process-transcription\"\n",
    "\n",
    "async def process_job(job: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Process a single job by:\n",
    "      - Converting each input file to a uniform mono WAV file.\n",
    "      - Sending the converted file paths to the ASR and (if enabled) diarization endpoints concurrently.\n",
    "      - Extracting the file-specific transcription and, if diarization is enabled, running the transcription processing endpoint.\n",
    "      - Updating the job with the final transcription (speech bubbles) and a timestamp.\n",
    "    \n",
    "    If diarization is not enabled, the final transcription is produced by \"beautifying\" the mono ASR output.\n",
    "    \"\"\"\n",
    "    temp_files = []  # Track temporary files for cleanup.\n",
    "    job_id = job.get(\"job_id\", \"unknown\")\n",
    "    # Start timing the job processing\n",
    "    start_time = datetime.datetime.now()\n",
    "\n",
    "    try:\n",
    "        print(f\"Processing job_id: {job_id}\")\n",
    "        # Extract original file paths from job.\n",
    "        orig_file_paths = ensure_list(job.get(\"files\"))\n",
    "        print(f\"{job_id}: Original file paths: {orig_file_paths}\")\n",
    "        \n",
    "        # Calculate total size of the original files in MB and update job[\"size\"]\n",
    "        total_size_bytes = 0\n",
    "        for path in orig_file_paths:\n",
    "            if os.path.exists(path):\n",
    "                total_size_bytes += os.path.getsize(path)\n",
    "            else:\n",
    "                print(f\"{job_id}: File not found: {path}\")\n",
    "        job[\"size\"] = total_size_bytes / (1024 * 1024)  # Convert bytes to MB\n",
    "        print(f\"{job_id}: Total size in MB: {job['size']}\")\n",
    "        \n",
    "        # Convert each file to a uniform mono WAV.\n",
    "        converted_paths = []\n",
    "        for orig_path in orig_file_paths:\n",
    "            tmp_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\")\n",
    "            tmp_file_path = tmp_file.name\n",
    "            tmp_file.close()\n",
    "            print(f\"{job_id}: Converting {orig_path} to mono WAV at {tmp_file_path}\")\n",
    "            try:\n",
    "                convert_to_mono_wav(orig_path, tmp_file_path)\n",
    "                converted_paths.append(tmp_file_path)\n",
    "                temp_files.append(tmp_file_path)\n",
    "            except Exception as conv_err:\n",
    "                print(f\"{job_id}: Conversion failed for {orig_path}: {conv_err}\")\n",
    "        \n",
    "        if not converted_paths:\n",
    "            raise RuntimeError(\"No files were successfully converted.\")\n",
    "        print(f\"{job_id}: Converted file paths: {converted_paths}\")\n",
    "        \n",
    "        # Prepare endpoint URLs and parameters.\n",
    "        asr_url = ASR_URL\n",
    "        diar_url = DIAR_URL\n",
    "        process_url = PROCESS_URL\n",
    "        source_data = job.get(\"source_data\", {})\n",
    "        params = {}\n",
    "        if source_data.get(\"num_speakers\"):\n",
    "            params[\"num_speakers\"] = source_data[\"num_speakers\"]\n",
    "        \n",
    "        # Use a client with a custom timeout.\n",
    "        async with httpx.AsyncClient(timeout=httpx.Timeout(ASR_TIMEOUT)) as client:\n",
    "            # Start ASR task.\n",
    "            asr_task = client.post(asr_url, json=converted_paths)\n",
    "            \n",
    "            # Start diarization task concurrently if diarization is enabled.\n",
    "            diar_task = None\n",
    "            if source_data.get(\"diarization\"):\n",
    "                print(f\"{job_id}: Sending request to Diarization endpoint: {diar_url}\")\n",
    "                print(f\"{job_id}: Diarization payload: {converted_paths} with params: {params}\")\n",
    "                diar_task = client.post(diar_url, params=params, json=converted_paths)\n",
    "            \n",
    "            # Launch tasks concurrently.\n",
    "            if diar_task is not None:\n",
    "                asr_response, diar_response = await asyncio.gather(asr_task, diar_task)\n",
    "            else:\n",
    "                asr_response = await asr_task\n",
    "                diar_response = None\n",
    "            \n",
    "            # Process ASR response.\n",
    "            print(f\"{job_id}: ASR response status: {asr_response.status_code}\")\n",
    "            if asr_response.status_code != 200:\n",
    "                print(f\"{job_id}: ASR response content: {asr_response.text}\")\n",
    "            try:\n",
    "                asr_data = asr_response.json()\n",
    "            except Exception as asr_err:\n",
    "                print(f\"{job_id}: Error decoding ASR response: {asr_err}\")\n",
    "                asr_data = {}\n",
    "    \n",
    "            # Process diarization response (if applicable).\n",
    "            if diar_response is not None:\n",
    "                print(f\"{job_id}: Diarization response status: {diar_response.status_code}\")\n",
    "                if diar_response.status_code != 200:\n",
    "                    print(f\"{job_id}: Diarization response content: {diar_response.text}\")\n",
    "                try:\n",
    "                    diarization_data = diar_response.json()\n",
    "                except Exception as diar_err:\n",
    "                    print(f\"{job_id}: Error decoding Diarization response: {diar_err}\")\n",
    "                    diarization_data = {}\n",
    "            else:\n",
    "                diarization_data = {}\n",
    "        \n",
    "        # Print the raw diarization output.\n",
    "        print(f\"{job_id}: Raw diarization output:\", diarization_data)\n",
    "    \n",
    "        # Transform diarization_data to a list if necessary.\n",
    "        if isinstance(diarization_data, dict) and len(diarization_data) > 0:\n",
    "            print(f\"{job_id}: Transforming diarization data from dict to list.\")\n",
    "            file_key_for_diar = job.get(\"file_name\", list(diarization_data.keys())[0])\n",
    "            diarization_list = diarization_data.get(file_key_for_diar, {}).get(\"diarization\", [])\n",
    "            diarization_data = diarization_list\n",
    "        else:\n",
    "            diarization_data = []\n",
    "    \n",
    "        # For the ASR transcription, extract the file-specific transcription.\n",
    "        if isinstance(asr_data, dict) and len(asr_data) > 0:\n",
    "            print(f\"{job_id}: Extracting file-specific ASR transcription.\")\n",
    "            file_key_for_asr = job.get(\"file_name\", list(asr_data.keys())[0])\n",
    "            transcription_data = asr_data.get(file_key_for_asr, [])\n",
    "        else:\n",
    "            raise ValueError(\"ASR transcription data must be a non-empty dict with file keys.\")\n",
    "    \n",
    "        # If diarization is enabled, process transcription with alignment;\n",
    "        # otherwise, \"beautify\" the mono ASR transcription using our helper function.\n",
    "        if source_data.get(\"diarization\"):\n",
    "            process_payload = {\n",
    "                \"transcription\": transcription_data,\n",
    "                \"diarization\": diarization_data\n",
    "            }\n",
    "            print(f\"{job_id}: Process-transcription payload:\", process_payload)\n",
    "            \n",
    "            async with httpx.AsyncClient(timeout=httpx.Timeout(DIAR_TIMEOUT)) as client:\n",
    "                process_response = await client.post(process_url, json=process_payload)\n",
    "                print(f\"{job_id}: Process-transcription response status:\", process_response.status_code)\n",
    "                if process_response.status_code != 200:\n",
    "                    print(f\"{job_id}: Process-transcription response content:\", process_response.text)\n",
    "                try:\n",
    "                    process_data = process_response.json()\n",
    "                except Exception as proc_err:\n",
    "                    print(f\"{job_id}: Error decoding Process-transcription response:\", proc_err)\n",
    "                    process_data = {}\n",
    "            final_transcription = process_data.get(\"speech_bubbles\")\n",
    "        else:\n",
    "            print(f\"{job_id}: Diarization not enabled. Beautifying ASR transcription output.\")\n",
    "            # Call our helper function to beautify the mono ASR transcription.\n",
    "            final_transcription = create_speech_bubbles_mono(\n",
    "                asr_transcription=transcription_data,\n",
    "                pause_threshold=PAUSE_THRESHOLD,\n",
    "                max_duration=MAX_SPEECH_BUBBLE\n",
    "            )\n",
    "    \n",
    "        # Update the job with the final transcription, timestamp, and time taken.\n",
    "        job[\"transcription\"] = final_transcription\n",
    "        if job.get(\"transcription\"):\n",
    "            # Transcription field is non-empty\n",
    "            job[\"status\"] = \"transcribed\"\n",
    "        else:\n",
    "            # Transcription field is empty or None\n",
    "            job[\"status\"] = \"error\"\n",
    "        job[\"transcribed_at\"] = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "        # Calculate time taken (in seconds) and update the job.\n",
    "        time_taken = (datetime.datetime.now() - start_time).total_seconds()\n",
    "        job[\"time_taken\"] = time_taken\n",
    "        print(f\"{job_id}: Job updated with transcription, timestamp, and time_taken: {time_taken} seconds.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing job_id {job_id}: {e}\")\n",
    "        traceback.print_exc()\n",
    "    finally:\n",
    "        # Cleanup temporary files.\n",
    "        for tmp_file in temp_files:\n",
    "            try:\n",
    "                os.remove(tmp_file)\n",
    "                print(f\"{job_id}: Removed temporary file: {tmp_file}\")\n",
    "            except Exception as rem_err:\n",
    "                print(f\"{job_id}: Error removing temporary file {tmp_file}: {rem_err}\")\n",
    "    return job\n",
    "\n",
    "async def process_jobs(jobs: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n",
    "    \n",
    "    results = await asyncio.gather(*(process_job(job) for job in jobs))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing job_id: 60\n",
      "60: Original file paths: ['C:/Users/Alex/golos-hub-back/uploads/2025/03/02/144323ec-025a-4034-a897-10d942666609.wav']\n",
      "60: Total size in MB: 0.060004234313964844\n",
      "60: Converting C:/Users/Alex/golos-hub-back/uploads/2025/03/02/144323ec-025a-4034-a897-10d942666609.wav to mono WAV at C:\\Users\\Alex\\AppData\\Local\\Temp\\tmpa5vox4z7.wav\n",
      "60: Converted file paths: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmpa5vox4z7.wav']\n",
      "60: Sending request to Diarization endpoint: http://127.0.0.1:8001/diarize_audio_bulk_local\n",
      "60: Diarization payload: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmpa5vox4z7.wav'] with params: {}\n",
      "Processing job_id: 57\n",
      "57: Original file paths: ['C:/Users/Alex/golos-hub-back/uploads/2025/02/04/a352a068-a7d8-476c-af1c-1bd0c9895c2e.MOV']\n",
      "57: Total size in MB: 1618.7826070785522\n",
      "57: Converting C:/Users/Alex/golos-hub-back/uploads/2025/02/04/a352a068-a7d8-476c-af1c-1bd0c9895c2e.MOV to mono WAV at C:\\Users\\Alex\\AppData\\Local\\Temp\\tmporc9otof.wav\n",
      "57: Converted file paths: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmporc9otof.wav']\n",
      "57: Sending request to Diarization endpoint: http://127.0.0.1:8001/diarize_audio_bulk_local\n",
      "57: Diarization payload: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmporc9otof.wav'] with params: {}\n",
      "Processing job_id: 58\n",
      "58: Original file paths: ['C:/Users/Alex/golos-hub-back/uploads/2025/02/04/6338698c-fb2c-4029-af2d-a7b2f1ee524b.MOV']\n",
      "58: Total size in MB: 4.728764533996582\n",
      "58: Converting C:/Users/Alex/golos-hub-back/uploads/2025/02/04/6338698c-fb2c-4029-af2d-a7b2f1ee524b.MOV to mono WAV at C:\\Users\\Alex\\AppData\\Local\\Temp\\tmpdceaylqr.wav\n",
      "58: Converted file paths: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmpdceaylqr.wav']\n",
      "58: Sending request to Diarization endpoint: http://127.0.0.1:8001/diarize_audio_bulk_local\n",
      "58: Diarization payload: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmpdceaylqr.wav'] with params: {}\n",
      "Processing job_id: 59\n",
      "59: Original file paths: ['C:/Users/Alex/golos-hub-back/uploads/2025/02/04/e2796736-feb5-4f98-a7ed-0a80631fc21c.MOV']\n",
      "59: Total size in MB: 3.990297317504883\n",
      "59: Converting C:/Users/Alex/golos-hub-back/uploads/2025/02/04/e2796736-feb5-4f98-a7ed-0a80631fc21c.MOV to mono WAV at C:\\Users\\Alex\\AppData\\Local\\Temp\\tmp1h229t_0.wav\n",
      "59: Converted file paths: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmp1h229t_0.wav']\n",
      "59: Sending request to Diarization endpoint: http://127.0.0.1:8001/diarize_audio_bulk_local\n",
      "59: Diarization payload: ['C:\\\\Users\\\\Alex\\\\AppData\\\\Local\\\\Temp\\\\tmp1h229t_0.wav'] with params: {}\n",
      "59: ASR response status: 200\n",
      "59: Diarization response status: 200\n",
      "59: Raw diarization output: {'tmp1h229t_0.wav': {'diarization': []}}\n",
      "59: Transforming diarization data from dict to list.\n",
      "59: Extracting file-specific ASR transcription.\n",
      "59: Process-transcription payload: {'transcription': {'Speaker 0': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 8.88, 'text': ' Спасибо за просмотр!', 'tokens': [50415, 29219, 4396, 21109, 11128, 0, 50465], 'temperature': 0.0, 'avg_logprob': -0.785002589225769, 'compression_ratio': 0.8222222222222222, 'no_speech_prob': 1.0815202206027053e-10, 'words': [{'word': ' Спасибо', 'start': 0.0, 'end': 0.32, 'probability': 0.07173947244882584}, {'word': ' за', 'start': 0.32, 'end': 5.48, 'probability': 0.7349920272827148}, {'word': ' просмотр!', 'start': 5.48, 'end': 8.88, 'probability': 0.8349382877349854}]}]}, 'diarization': []}\n",
      "59: Process-transcription response status: 200\n",
      "59: Job updated with transcription, timestamp, and time_taken: 26.005598 seconds.\n",
      "59: Removed temporary file: C:\\Users\\Alex\\AppData\\Local\\Temp\\tmp1h229t_0.wav\n",
      "60: ASR response status: 200\n",
      "60: Diarization response status: 200\n",
      "60: Raw diarization output: {'tmpa5vox4z7.wav': {'diarization': [{'start': 0.5372187500000001, 'end': 3.15284375, 'speaker': 'SPEAKER_02'}, {'start': 4.1822187500000005, 'end': 4.8572187499999995, 'speaker': 'SPEAKER_03'}, {'start': 5.16096875, 'end': 6.98346875, 'speaker': 'SPEAKER_03'}, {'start': 7.50659375, 'end': 8.78909375, 'speaker': 'SPEAKER_02'}, {'start': 8.78909375, 'end': 8.856593750000002, 'speaker': 'SPEAKER_03'}, {'start': 10.20659375, 'end': 10.864718750000002, 'speaker': 'SPEAKER_03'}, {'start': 11.168468750000002, 'end': 11.89409375, 'speaker': 'SPEAKER_03'}, {'start': 12.957218750000003, 'end': 13.68284375, 'speaker': 'SPEAKER_03'}, {'start': 14.05409375, 'end': 14.745968750000003, 'speaker': 'SPEAKER_03'}, {'start': 16.66971875, 'end': 17.63159375, 'speaker': 'SPEAKER_03'}, {'start': 20.11221875, 'end': 20.48346875, 'speaker': 'SPEAKER_00'}, {'start': 20.85471875, 'end': 21.95159375, 'speaker': 'SPEAKER_00'}, {'start': 23.21721875, 'end': 24.58409375, 'speaker': 'SPEAKER_03'}, {'start': 25.292843750000003, 'end': 25.309718750000002, 'speaker': 'SPEAKER_00'}, {'start': 25.309718750000002, 'end': 26.23784375, 'speaker': 'SPEAKER_03'}, {'start': 27.80721875, 'end': 29.258468750000002, 'speaker': 'SPEAKER_03'}, {'start': 29.44409375, 'end': 30.76034375, 'speaker': 'SPEAKER_03'}, {'start': 31.11471875, 'end': 31.317218750000002, 'speaker': 'SPEAKER_03'}, {'start': 31.317218750000002, 'end': 34.860968750000005, 'speaker': 'SPEAKER_01'}, {'start': 34.42221875, 'end': 34.979093750000004, 'speaker': 'SPEAKER_03'}, {'start': 36.227843750000005, 'end': 37.78034375, 'speaker': 'SPEAKER_03'}, {'start': 37.32471875, 'end': 38.21909375, 'speaker': 'SPEAKER_01'}]}}\n",
      "60: Transforming diarization data from dict to list.\n",
      "60: Extracting file-specific ASR transcription.\n",
      "60: Process-transcription payload: {'transcription': {'Speaker 0': [{'id': 0, 'seek': 0, 'start': 0.56, 'end': 2.9, 'text': ' Газпром Энергосбыт, оператор Оксана, здравствуйте.', 'tokens': [50393, 7247, 1990, 1354, 21503, 5381, 489, 1135, 4567, 461, 1552, 14043, 11, 7683, 13126, 2542, 48984, 461, 15253, 11, 7608, 36359, 13, 50507], 'temperature': 0.0, 'avg_logprob': -0.46215614905724156, 'compression_ratio': 1.6991150442477876, 'no_speech_prob': 1.7232904339636868e-11, 'words': [{'word': ' Газпром', 'start': 0.5499999999999998, 'end': 0.98, 'probability': 0.801289938390255}, {'word': ' Энергосбыт,', 'start': 0.98, 'end': 1.64, 'probability': 0.8745658099651337}, {'word': ' оператор', 'start': 1.7, 'end': 2.04, 'probability': 0.9923150936762491}, {'word': ' Оксана,', 'start': 2.04, 'end': 2.3, 'probability': 0.752234677473704}, {'word': ' здравствуйте.', 'start': 2.4, 'end': 2.9, 'probability': 0.9938820600509644}]}, {'id': 1, 'seek': 0, 'start': 3.84, 'end': 6.94, 'text': ' Здравствуйте. Мне бы показания счетчика передали.', 'tokens': [50570, 17613, 36359, 13, 23204, 2768, 21147, 8831, 23812, 1094, 753, 17286, 15621, 4071, 13, 50712], 'temperature': 0.0, 'avg_logprob': -0.46215614905724156, 'compression_ratio': 1.6991150442477876, 'no_speech_prob': 1.7232904339636868e-11, 'words': [{'word': ' Здравствуйте.', 'start': 3.84, 'end': 4.7, 'probability': 0.9952983558177948}, {'word': ' Мне', 'start': 5.1, 'end': 5.36, 'probability': 0.9425530433654785}, {'word': ' бы', 'start': 5.36, 'end': 5.44, 'probability': 0.6796823143959045}, {'word': ' показания', 'start': 5.44, 'end': 6.12, 'probability': 0.9238972663879395}, {'word': ' счетчика', 'start': 6.12, 'end': 6.52, 'probability': 0.9068150818347931}, {'word': ' передали.', 'start': 6.52, 'end': 6.94, 'probability': 0.7570602893829346}]}, {'id': 2, 'seek': 0, 'start': 7.38, 'end': 8.7, 'text': ' Лицевой счет называйте.', 'tokens': [50740, 7853, 435, 22898, 1700, 23812, 1094, 20922, 10330, 13, 50801], 'temperature': 0.0, 'avg_logprob': -0.46215614905724156, 'compression_ratio': 1.6991150442477876, 'no_speech_prob': 1.7232904339636868e-11, 'words': [{'word': ' Лицевой', 'start': 7.38, 'end': 7.94, 'probability': 0.8074713721871376}, {'word': ' счет', 'start': 7.94, 'end': 8.2, 'probability': 0.9992547333240509}, {'word': ' называйте.', 'start': 8.2, 'end': 8.7, 'probability': 0.973668783903122}]}, {'id': 3, 'seek': 0, 'start': 10.06, 'end': 17.26, 'text': ' Ага, так. 0,1, 3,0, 20, 3,19.', 'tokens': [50873, 3450, 18706, 11, 2936, 13, 1958, 11, 16, 11, 805, 11, 15, 11, 945, 11, 805, 11, 3405, 13, 51237], 'temperature': 0.0, 'avg_logprob': -0.46215614905724156, 'compression_ratio': 1.6991150442477876, 'no_speech_prob': 1.7232904339636868e-11, 'words': [{'word': ' Ага,', 'start': 10.06, 'end': 10.54, 'probability': 0.8773524463176727}, {'word': ' так.', 'start': 10.62, 'end': 10.8, 'probability': 0.9793756604194641}, {'word': ' 0', 'start': 11.18, 'end': 11.42, 'probability': 0.7155361771583557}, {'word': ',1,', 'start': 11.42, 'end': 11.78, 'probability': 0.6619143635034561}, {'word': ' 3', 'start': 12.16, 'end': 13.14, 'probability': 0.9359394311904907}, {'word': ',0,', 'start': 13.14, 'end': 13.38, 'probability': 0.7577612996101379}, {'word': ' 20,', 'start': 13.84, 'end': 14.54, 'probability': 0.7130633592605591}, {'word': ' 3', 'start': 15.4, 'end': 16.86, 'probability': 0.9985276460647583}, {'word': ',19.', 'start': 16.86, 'end': 17.26, 'probability': 0.9920030832290649}]}, {'id': 4, 'seek': 0, 'start': 20.44, 'end': 21.72, 'text': ' Фамилию скажите.', 'tokens': [51387, 13196, 5150, 1675, 1148, 21938, 5878, 13, 51452], 'temperature': 0.0, 'avg_logprob': -0.46215614905724156, 'compression_ratio': 1.6991150442477876, 'no_speech_prob': 1.7232904339636868e-11, 'words': [{'word': ' Фамилию', 'start': 20.44, 'end': 21.3, 'probability': 0.973850205540657}, {'word': ' скажите.', 'start': 21.3, 'end': 21.72, 'probability': 0.853005975484848}]}, {'id': 5, 'seek': 0, 'start': 22.88, 'end': 24.52, 'text': ' Имущенко Александр Ушевич.', 'tokens': [51522, 3272, 11147, 2000, 37794, 44938, 481, 6523, 1198, 42110, 13, 51593], 'temperature': 0.0, 'avg_logprob': -0.46215614905724156, 'compression_ratio': 1.6991150442477876, 'no_speech_prob': 1.7232904339636868e-11, 'words': [{'word': ' Имущенко', 'start': 22.88, 'end': 23.74, 'probability': 0.5713406428694725}, {'word': ' Александр', 'start': 23.74, 'end': 24.18, 'probability': 0.9098004400730133}, {'word': ' Ушевич.', 'start': 24.18, 'end': 24.52, 'probability': 0.38731176654497784}]}, {'id': 6, 'seek': 0, 'start': 25.22, 'end': 26.08, 'text': ' Извините, показания?', 'tokens': [51628, 24588, 36823, 5878, 11, 21147, 8831, 30, 51669], 'temperature': 0.0, 'avg_logprob': -0.46215614905724156, 'compression_ratio': 1.6991150442477876, 'no_speech_prob': 1.7232904339636868e-11, 'words': [{'word': ' Извините,', 'start': 25.22, 'end': 25.58, 'probability': 0.48756663997968036}, {'word': ' показания?', 'start': 25.84, 'end': 26.08, 'probability': 0.994730144739151}]}, {'id': 7, 'seek': 2608, 'start': 27.48, 'end': 30.08, 'text': ' Показание 32, 231.', 'tokens': [50415, 2608, 2637, 1990, 9633, 8858, 11, 6673, 16, 13, 50565], 'temperature': 0.0, 'avg_logprob': -0.5063895663699588, 'compression_ratio': 1.264367816091954, 'no_speech_prob': 1.3847929747345944e-11, 'words': [{'word': ' Показание', 'start': 27.48, 'end': 28.26, 'probability': 0.8233055621385574}, {'word': ' 32,', 'start': 28.26, 'end': 29.0, 'probability': 0.9544137716293335}, {'word': ' 231.', 'start': 29.22, 'end': 30.08, 'probability': 0.9616676867008209}]}, {'id': 8, 'seek': 2608, 'start': 31.939999999999998, 'end': 34.62, 'text': ' 32, 231. Показание принято?', 'tokens': [50615, 8858, 11, 6673, 16, 13, 2608, 2637, 1990, 9633, 16003, 681, 860, 30, 50765], 'temperature': 0.0, 'avg_logprob': -0.5063895663699588, 'compression_ratio': 1.264367816091954, 'no_speech_prob': 1.3847929747345944e-11, 'words': [{'word': ' 32,', 'start': 31.939999999999998, 'end': 32.72, 'probability': 0.9726258516311646}, {'word': ' 231.', 'start': 32.72, 'end': 33.5, 'probability': 0.998165488243103}, {'word': ' Показание', 'start': 33.64, 'end': 34.18, 'probability': 0.9381821900606155}, {'word': ' принято?', 'start': 34.18, 'end': 34.62, 'probability': 0.9982048471768697}]}, {'id': 9, 'seek': 2608, 'start': 34.96, 'end': 37.56, 'text': ' Да. Спасибо за что-то.', 'tokens': [50815, 9149, 13, 29219, 4396, 2143, 12, 860, 13, 50915], 'temperature': 0.0, 'avg_logprob': -0.5063895663699588, 'compression_ratio': 1.264367816091954, 'no_speech_prob': 1.3847929747345944e-11, 'words': [{'word': ' Да.', 'start': 34.96, 'end': 34.96, 'probability': 0.2692427635192871}, {'word': ' Спасибо', 'start': 36.18, 'end': 36.94, 'probability': 0.8733417391777039}, {'word': ' за', 'start': 36.94, 'end': 37.22, 'probability': 0.9732628464698792}, {'word': ' что', 'start': 37.22, 'end': 37.36, 'probability': 0.25553086400032043}, {'word': '-то.', 'start': 37.36, 'end': 37.56, 'probability': 0.6392825841903687}]}]}, 'diarization': [{'start': 0.5372187500000001, 'end': 3.15284375, 'speaker': 'SPEAKER_02'}, {'start': 4.1822187500000005, 'end': 4.8572187499999995, 'speaker': 'SPEAKER_03'}, {'start': 5.16096875, 'end': 6.98346875, 'speaker': 'SPEAKER_03'}, {'start': 7.50659375, 'end': 8.78909375, 'speaker': 'SPEAKER_02'}, {'start': 8.78909375, 'end': 8.856593750000002, 'speaker': 'SPEAKER_03'}, {'start': 10.20659375, 'end': 10.864718750000002, 'speaker': 'SPEAKER_03'}, {'start': 11.168468750000002, 'end': 11.89409375, 'speaker': 'SPEAKER_03'}, {'start': 12.957218750000003, 'end': 13.68284375, 'speaker': 'SPEAKER_03'}, {'start': 14.05409375, 'end': 14.745968750000003, 'speaker': 'SPEAKER_03'}, {'start': 16.66971875, 'end': 17.63159375, 'speaker': 'SPEAKER_03'}, {'start': 20.11221875, 'end': 20.48346875, 'speaker': 'SPEAKER_00'}, {'start': 20.85471875, 'end': 21.95159375, 'speaker': 'SPEAKER_00'}, {'start': 23.21721875, 'end': 24.58409375, 'speaker': 'SPEAKER_03'}, {'start': 25.292843750000003, 'end': 25.309718750000002, 'speaker': 'SPEAKER_00'}, {'start': 25.309718750000002, 'end': 26.23784375, 'speaker': 'SPEAKER_03'}, {'start': 27.80721875, 'end': 29.258468750000002, 'speaker': 'SPEAKER_03'}, {'start': 29.44409375, 'end': 30.76034375, 'speaker': 'SPEAKER_03'}, {'start': 31.11471875, 'end': 31.317218750000002, 'speaker': 'SPEAKER_03'}, {'start': 31.317218750000002, 'end': 34.860968750000005, 'speaker': 'SPEAKER_01'}, {'start': 34.42221875, 'end': 34.979093750000004, 'speaker': 'SPEAKER_03'}, {'start': 36.227843750000005, 'end': 37.78034375, 'speaker': 'SPEAKER_03'}, {'start': 37.32471875, 'end': 38.21909375, 'speaker': 'SPEAKER_01'}]}\n",
      "60: Process-transcription response status: 200\n",
      "60: Job updated with transcription, timestamp, and time_taken: 28.496237 seconds.\n",
      "60: Removed temporary file: C:\\Users\\Alex\\AppData\\Local\\Temp\\tmpa5vox4z7.wav\n",
      "58: ASR response status: 200\n",
      "58: Diarization response status: 200\n",
      "58: Raw diarization output: {'tmpdceaylqr.wav': {'diarization': [{'start': 0.03096875, 'end': 1.3134687500000002, 'speaker': 'SPEAKER_00'}, {'start': 3.11909375, 'end': 4.21596875, 'speaker': 'SPEAKER_00'}]}}\n",
      "58: Transforming diarization data from dict to list.\n",
      "58: Extracting file-specific ASR transcription.\n",
      "58: Process-transcription payload: {'transcription': {'Speaker 0': [{'id': 0, 'seek': 0, 'start': 0.0, 'end': 1.26, 'text': ' А чё морда такая злая?', 'tokens': [50367, 3450, 1358, 2882, 24127, 3444, 22075, 1423, 693, 4251, 30, 50427], 'temperature': 0.0, 'avg_logprob': -0.4771272277832031, 'compression_ratio': 1.0470588235294118, 'no_speech_prob': 3.1566225328072406e-11, 'words': [{'word': ' А', 'start': 0.0, 'end': 0.16, 'probability': 0.8153966069221497}, {'word': ' чё', 'start': 0.16, 'end': 0.34, 'probability': 0.6448061466217041}, {'word': ' морда', 'start': 0.34, 'end': 0.62, 'probability': 0.670138880610466}, {'word': ' такая', 'start': 0.62, 'end': 0.86, 'probability': 0.9758015871047974}, {'word': ' злая?', 'start': 0.86, 'end': 1.26, 'probability': 0.9962599674860636}]}, {'id': 1, 'seek': 0, 'start': 2.98, 'end': 4.12, 'text': ' Пределить мне чё-то хочешь?', 'tokens': [50521, 46825, 1414, 3258, 8531, 1358, 2882, 12, 860, 45656, 30, 50571], 'temperature': 0.0, 'avg_logprob': -0.4771272277832031, 'compression_ratio': 1.0470588235294118, 'no_speech_prob': 3.1566225328072406e-11, 'words': [{'word': ' Пределить', 'start': 2.98, 'end': 3.5, 'probability': 0.67645396788915}, {'word': ' мне', 'start': 3.5, 'end': 3.62, 'probability': 0.4260561764240265}, {'word': ' чё', 'start': 3.62, 'end': 3.82, 'probability': 0.8103470504283905}, {'word': '-то', 'start': 3.82, 'end': 3.84, 'probability': 0.918700784444809}, {'word': ' хочешь?', 'start': 3.84, 'end': 4.12, 'probability': 0.9966936111450195}]}]}, 'diarization': [{'start': 0.03096875, 'end': 1.3134687500000002, 'speaker': 'SPEAKER_00'}, {'start': 3.11909375, 'end': 4.21596875, 'speaker': 'SPEAKER_00'}]}\n",
      "58: Process-transcription response status: 200\n",
      "58: Job updated with transcription, timestamp, and time_taken: 28.023924 seconds.\n",
      "58: Removed temporary file: C:\\Users\\Alex\\AppData\\Local\\Temp\\tmpdceaylqr.wav\n",
      "57: ASR response status: 200\n",
      "57: Diarization response status: 200\n",
      "57: Raw diarization output: {'tmporc9otof.wav': {'diarization': [{'start': 0.03096875, 'end': 0.047843750000000004, 'speaker': 'SPEAKER_00'}, {'start': 1.8703437500000002, 'end': 5.8697187500000005, 'speaker': 'SPEAKER_00'}, {'start': 6.46034375, 'end': 17.54721875, 'speaker': 'SPEAKER_00'}, {'start': 18.15471875, 'end': 19.79159375, 'speaker': 'SPEAKER_00'}, {'start': 21.32721875, 'end': 22.829093750000002, 'speaker': 'SPEAKER_00'}, {'start': 101.06159375, 'end': 104.84159375, 'speaker': 'SPEAKER_00'}, {'start': 104.97659375, 'end': 105.02721875, 'speaker': 'SPEAKER_00'}, {'start': 105.09471875000001, 'end': 107.03534375000001, 'speaker': 'SPEAKER_00'}, {'start': 113.97096875000001, 'end': 114.03846875, 'speaker': 'SPEAKER_00'}, {'start': 114.91596875, 'end': 115.47284375000001, 'speaker': 'SPEAKER_00'}, {'start': 116.83971875, 'end': 120.58596875, 'speaker': 'SPEAKER_00'}, {'start': 118.71284375, 'end': 119.72534375000001, 'speaker': 'SPEAKER_01'}, {'start': 126.81284375000001, 'end': 129.02346875, 'speaker': 'SPEAKER_00'}, {'start': 129.12471875, 'end': 131.36909375000002, 'speaker': 'SPEAKER_00'}, {'start': 133.17471875, 'end': 144.02534375000002, 'speaker': 'SPEAKER_00'}, {'start': 134.99721875, 'end': 136.53284375, 'speaker': 'SPEAKER_01'}, {'start': 136.66784375, 'end': 137.08971875, 'speaker': 'SPEAKER_01'}, {'start': 141.66284375, 'end': 141.96659375000002, 'speaker': 'SPEAKER_01'}, {'start': 144.12659375, 'end': 144.68346875, 'speaker': 'SPEAKER_00'}, {'start': 144.80159375, 'end': 145.67909375000002, 'speaker': 'SPEAKER_00'}, {'start': 155.97284375, 'end': 156.20909375000002, 'speaker': 'SPEAKER_00'}, {'start': 158.41971875000002, 'end': 162.01409375, 'speaker': 'SPEAKER_00'}, {'start': 164.74784375000002, 'end': 164.76471875000001, 'speaker': 'SPEAKER_00'}]}}\n",
      "57: Transforming diarization data from dict to list.\n",
      "57: Extracting file-specific ASR transcription.\n",
      "57: Process-transcription payload: {'transcription': {'Speaker 0': [{'id': 0, 'seek': 0, 'start': 6.260000000000001, 'end': 8.18, 'text': ' Дверь просто так нельзя открыть.', 'tokens': [50415, 3401, 859, 9352, 8221, 2936, 33813, 27085, 1283, 13, 50715], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' Дверь', 'start': 6.260000000000001, 'end': 6.8, 'probability': 0.6899184038241705}, {'word': ' просто', 'start': 6.8, 'end': 7.1, 'probability': 0.8590007424354553}, {'word': ' так', 'start': 7.1, 'end': 7.32, 'probability': 0.9837049841880798}, {'word': ' нельзя', 'start': 7.32, 'end': 7.64, 'probability': 0.9556931257247925}, {'word': ' открыть.', 'start': 7.64, 'end': 8.18, 'probability': 0.9927040338516235}]}, {'id': 1, 'seek': 0, 'start': 8.3, 'end': 11.88, 'text': ' Здесь есть такой магнитный замочек, надо приложить пальчик, тогда открывается.', 'tokens': [50715, 23367, 5640, 13452, 27120, 47264, 4441, 13597, 4492, 2872, 11, 13256, 47251, 3258, 47226, 19536, 11, 21696, 44543, 6970, 13, 50965], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' Здесь', 'start': 8.3, 'end': 8.46, 'probability': 0.8235607743263245}, {'word': ' есть', 'start': 8.46, 'end': 8.78, 'probability': 0.9586604833602905}, {'word': ' такой', 'start': 8.78, 'end': 8.9, 'probability': 0.6683522462844849}, {'word': ' магнитный', 'start': 8.9, 'end': 9.38, 'probability': 0.90749059120814}, {'word': ' замочек,', 'start': 9.38, 'end': 9.88, 'probability': 0.7835521598656973}, {'word': ' надо', 'start': 9.94, 'end': 10.06, 'probability': 0.8229029774665833}, {'word': ' приложить', 'start': 10.06, 'end': 10.52, 'probability': 0.9897849559783936}, {'word': ' пальчик,', 'start': 10.52, 'end': 10.92, 'probability': 0.778317391872406}, {'word': ' тогда', 'start': 11.02, 'end': 11.18, 'probability': 0.9130821228027344}, {'word': ' открывается.', 'start': 11.18, 'end': 11.88, 'probability': 0.9633835554122925}]}, {'id': 2, 'seek': 0, 'start': 12.5, 'end': 14.7, 'text': ' Нужно нажимать, надо просто приложить пальчик.', 'tokens': [50965, 2410, 5726, 1234, 35675, 2165, 2209, 11, 13256, 8221, 47251, 3258, 47226, 19536, 13, 51115], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' Нужно', 'start': 12.5, 'end': 13.04, 'probability': 0.6435981343189875}, {'word': ' нажимать,', 'start': 13.04, 'end': 13.46, 'probability': 0.6446801672379175}, {'word': ' надо', 'start': 13.46, 'end': 13.62, 'probability': 0.5613095760345459}, {'word': ' просто', 'start': 13.62, 'end': 13.9, 'probability': 0.8535072207450867}, {'word': ' приложить', 'start': 13.9, 'end': 14.26, 'probability': 0.8233793675899506}, {'word': ' пальчик.', 'start': 14.26, 'end': 14.7, 'probability': 0.9781883060932159}]}, {'id': 3, 'seek': 0, 'start': 15.24, 'end': 15.98, 'text': ' Это что я предлагаю?', 'tokens': [51115, 6684, 2143, 2552, 46841, 3776, 30, 51215], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' Это', 'start': 15.24, 'end': 15.48, 'probability': 0.0898662582039833}, {'word': ' что', 'start': 15.48, 'end': 15.58, 'probability': 0.6340388059616089}, {'word': ' я', 'start': 15.58, 'end': 15.76, 'probability': 0.8146657347679138}, {'word': ' предлагаю?', 'start': 15.76, 'end': 15.98, 'probability': 0.5267847143113613}]}, {'id': 4, 'seek': 0, 'start': 15.98, 'end': 17.38, 'text': ' Это собака, я хочу тебя не берет.', 'tokens': [51215, 6684, 10450, 39558, 11, 2552, 22168, 12644, 1725, 24562, 1094, 13, 51315], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' Это', 'start': 15.98, 'end': 16.12, 'probability': 0.14538054168224335}, {'word': ' собака,', 'start': 16.12, 'end': 16.62, 'probability': 0.6393791735172272}, {'word': ' я', 'start': 16.72, 'end': 16.76, 'probability': 0.5487644076347351}, {'word': ' хочу', 'start': 16.76, 'end': 16.82, 'probability': 0.27507293224334717}, {'word': ' тебя', 'start': 16.82, 'end': 16.96, 'probability': 0.34192323684692383}, {'word': ' не', 'start': 16.96, 'end': 17.06, 'probability': 0.5199335813522339}, {'word': ' берет.', 'start': 17.06, 'end': 17.38, 'probability': 0.4598769545555115}]}, {'id': 5, 'seek': 0, 'start': 18.02, 'end': 19.38, 'text': ' У меня не нас не будет собак.', 'tokens': [51315, 6523, 6885, 1725, 6519, 1725, 7306, 10450, 1272, 13, 51415], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' У', 'start': 18.02, 'end': 18.38, 'probability': 0.6117764115333557}, {'word': ' меня', 'start': 18.38, 'end': 18.5, 'probability': 0.9785270690917969}, {'word': ' не', 'start': 18.5, 'end': 18.54, 'probability': 0.20694337785243988}, {'word': ' нас', 'start': 18.54, 'end': 18.86, 'probability': 0.4711304008960724}, {'word': ' не', 'start': 18.86, 'end': 18.98, 'probability': 0.9298699498176575}, {'word': ' будет', 'start': 18.98, 'end': 19.16, 'probability': 0.9375793933868408}, {'word': ' собак.', 'start': 19.16, 'end': 19.38, 'probability': 0.26739663630723953}]}, {'id': 6, 'seek': 0, 'start': 21.020000000000003, 'end': 22.74, 'text': ' Дверь с теплоразливым.', 'tokens': [51415, 3401, 859, 9352, 776, 38923, 693, 1717, 1990, 15054, 11250, 13, 51515], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' Дверь', 'start': 21.020000000000003, 'end': 21.560000000000002, 'probability': 0.928650438785553}, {'word': ' с', 'start': 21.560000000000002, 'end': 22.1, 'probability': 0.9167513847351074}, {'word': ' теплоразливым.', 'start': 22.1, 'end': 22.74, 'probability': 0.540758858124415}]}, {'id': 7, 'seek': 0, 'start': 25.08, 'end': 25.74, 'text': ' Ну, это ласка.', 'tokens': [51515, 7571, 11, 2691, 2344, 2019, 2833, 13, 51665], 'temperature': 0.0, 'avg_logprob': -0.5991566612606957, 'compression_ratio': 1.9348659003831417, 'no_speech_prob': 6.361799281817682e-11, 'words': [{'word': ' Ну,', 'start': 25.08, 'end': 25.32, 'probability': 0.11383602023124695}, {'word': ' это', 'start': 25.4, 'end': 25.48, 'probability': 0.38407689332962036}, {'word': ' ласка.', 'start': 25.48, 'end': 25.74, 'probability': 0.2424809510509173}]}, {'id': 8, 'seek': 2574, 'start': 32.86, 'end': 34.26, 'text': ' Спасибо.', 'tokens': [50415, 29219, 13, 50465], 'temperature': 0.2, 'avg_logprob': -1.0572804450988769, 'compression_ratio': 0.625, 'no_speech_prob': 7.230013809866875e-11, 'words': [{'word': ' Спасибо.', 'start': 32.86, 'end': 34.26, 'probability': 0.16834741830825806}]}, {'id': 9, 'seek': 5574, 'start': 56.339999999999996, 'end': 57.6, 'text': ' Да, да.', 'tokens': [50415, 9149, 11, 8995, 13, 50465], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Да,', 'start': 56.339999999999996, 'end': 56.98, 'probability': 0.024612102657556534}, {'word': ' да.', 'start': 57.2, 'end': 57.6, 'probability': 0.39119285345077515}]}, {'id': 10, 'seek': 5574, 'start': 58.12, 'end': 58.28, 'text': ' Да, да.', 'tokens': [50465, 9149, 11, 8995, 13, 50515], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Да,', 'start': 58.12, 'end': 58.12, 'probability': 0.2219935804605484}, {'word': ' да.', 'start': 58.12, 'end': 58.28, 'probability': 0.9462389349937439}]}, {'id': 11, 'seek': 5574, 'start': 59.3, 'end': 61.56, 'text': ' Вот у нас парка-плата.', 'tokens': [50515, 9756, 1595, 6519, 11813, 2833, 12, 1354, 693, 19808, 13, 50665], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Вот', 'start': 59.3, 'end': 59.48, 'probability': 0.264105886220932}, {'word': ' у', 'start': 59.48, 'end': 59.48, 'probability': 0.08217489719390869}, {'word': ' нас', 'start': 59.48, 'end': 60.5, 'probability': 0.9929848313331604}, {'word': ' парка', 'start': 60.5, 'end': 61.18, 'probability': 0.6161281019449234}, {'word': '-плата.', 'start': 61.18, 'end': 61.56, 'probability': 0.3630969151854515}]}, {'id': 12, 'seek': 5574, 'start': 63.12, 'end': 63.76, 'text': ' Возможно.', 'tokens': [50665, 2348, 33968, 13, 50765], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Возможно.', 'start': 63.12, 'end': 63.76, 'probability': 0.5836265534162521}]}, {'id': 13, 'seek': 5574, 'start': 64.08, 'end': 64.48, 'text': ' Возможно.', 'tokens': [50765, 2348, 33968, 13, 50815], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Возможно.', 'start': 64.08, 'end': 64.48, 'probability': 0.41894030570983887}]}, {'id': 14, 'seek': 5574, 'start': 64.52, 'end': 67.12, 'text': ' В связи с срекультурацией, вот как нам еще и на мишу.', 'tokens': [50815, 2348, 22430, 435, 776, 776, 481, 2872, 13618, 13549, 3580, 3706, 2345, 11, 5505, 3014, 11401, 9910, 1006, 1470, 1084, 9919, 585, 13, 50965], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' В', 'start': 64.52, 'end': 64.54, 'probability': 0.275799423456192}, {'word': ' связи', 'start': 64.54, 'end': 64.82, 'probability': 0.5201075281947851}, {'word': ' с', 'start': 64.82, 'end': 64.94, 'probability': 0.9519790410995483}, {'word': ' срекультурацией,', 'start': 64.94, 'end': 65.72, 'probability': 0.5202066311612725}, {'word': ' вот', 'start': 65.76, 'end': 65.88, 'probability': 0.6343292593955994}, {'word': ' как', 'start': 65.88, 'end': 66.06, 'probability': 0.8594600558280945}, {'word': ' нам', 'start': 66.06, 'end': 66.32, 'probability': 0.2551129460334778}, {'word': ' еще', 'start': 66.32, 'end': 66.6, 'probability': 0.5949639678001404}, {'word': ' и', 'start': 66.6, 'end': 66.92, 'probability': 0.14629198610782623}, {'word': ' на', 'start': 66.92, 'end': 66.92, 'probability': 0.08728954941034317}, {'word': ' мишу.', 'start': 66.92, 'end': 67.12, 'probability': 0.22542391469081244}]}, {'id': 15, 'seek': 5574, 'start': 67.16, 'end': 67.62, 'text': ' Большая.', 'tokens': [50965, 5697, 24110, 4251, 13, 51015], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Большая.', 'start': 67.16, 'end': 67.62, 'probability': 0.39312579731146496}]}, {'id': 16, 'seek': 5574, 'start': 68.1, 'end': 68.18, 'text': ' Да.', 'tokens': [51015, 9149, 13, 51065], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Да.', 'start': 68.1, 'end': 68.18, 'probability': 0.5969096422195435}]}, {'id': 17, 'seek': 5574, 'start': 69.68, 'end': 69.76, 'text': ' Вот.', 'tokens': [51065, 9756, 13, 51115], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Вот.', 'start': 69.68, 'end': 69.76, 'probability': 0.18633101880550385}]}, {'id': 18, 'seek': 5574, 'start': 69.76, 'end': 71.02, 'text': ' Аккуратия или третий.', 'tokens': [51115, 3450, 755, 4401, 11157, 7409, 8101, 7550, 1094, 6251, 13, 51165], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Аккуратия', 'start': 69.76, 'end': 70.4, 'probability': 0.28443917427212}, {'word': ' или', 'start': 70.4, 'end': 70.68, 'probability': 0.2101447582244873}, {'word': ' третий.', 'start': 70.68, 'end': 71.02, 'probability': 0.6176649431387583}]}, {'id': 19, 'seek': 5574, 'start': 71.16, 'end': 72.62, 'text': ' Я тоже, например, не могу.', 'tokens': [51165, 4857, 12251, 11, 24044, 11, 1725, 22951, 13, 51265], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Я', 'start': 71.16, 'end': 71.66, 'probability': 0.170852392911911}, {'word': ' тоже,', 'start': 71.66, 'end': 71.98, 'probability': 0.2560751736164093}, {'word': ' например,', 'start': 72.4, 'end': 72.4, 'probability': 0.35436275601387024}, {'word': ' не', 'start': 72.52, 'end': 72.62, 'probability': 0.20647777616977692}, {'word': ' могу.', 'start': 72.62, 'end': 72.62, 'probability': 0.35872116684913635}]}, {'id': 20, 'seek': 5574, 'start': 73.14, 'end': 75.14, 'text': ' Нет, я тоже.', 'tokens': [51265, 21249, 11, 2552, 12251, 13, 51315], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Нет,', 'start': 73.14, 'end': 73.48, 'probability': 0.7614544034004211}, {'word': ' я', 'start': 74.66, 'end': 75.14, 'probability': 0.12733614444732666}, {'word': ' тоже.', 'start': 75.14, 'end': 75.14, 'probability': 0.45957502722740173}]}, {'id': 21, 'seek': 5574, 'start': 75.14, 'end': 75.46, 'text': ' Нет, но могу.', 'tokens': [51315, 21249, 11, 6035, 22951, 13, 51365], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Нет,', 'start': 75.14, 'end': 75.14, 'probability': 0.30812984704971313}, {'word': ' но', 'start': 75.14, 'end': 75.14, 'probability': 0.03420180827379227}, {'word': ' могу.', 'start': 75.14, 'end': 75.46, 'probability': 0.17705348134040833}]}, {'id': 22, 'seek': 5574, 'start': 76.3, 'end': 78.12, 'text': ' Нет, я тоже.', 'tokens': [51365, 21249, 11, 2552, 12251, 13, 51465], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Нет,', 'start': 76.3, 'end': 76.94, 'probability': 0.8888568878173828}, {'word': ' я', 'start': 77.34, 'end': 77.96, 'probability': 0.40029773116111755}, {'word': ' тоже.', 'start': 77.96, 'end': 78.12, 'probability': 0.7167362570762634}]}, {'id': 23, 'seek': 5574, 'start': 78.94, 'end': 79.58, 'text': ' Вот.', 'tokens': [51465, 9756, 13, 51565], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Вот.', 'start': 78.94, 'end': 79.58, 'probability': 0.5559307336807251}]}, {'id': 24, 'seek': 5574, 'start': 79.94, 'end': 81.9, 'text': ' Дальше я приду в слухе своей телевидей.', 'tokens': [51565, 3401, 3842, 5246, 2552, 21255, 585, 740, 4766, 11576, 387, 25346, 15619, 44278, 2345, 13, 51665], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Дальше', 'start': 79.94, 'end': 80.42, 'probability': 0.991959015528361}, {'word': ' я', 'start': 80.42, 'end': 80.56, 'probability': 0.24556981027126312}, {'word': ' приду', 'start': 80.56, 'end': 80.76, 'probability': 0.4149773642420769}, {'word': ' в', 'start': 80.76, 'end': 80.88, 'probability': 0.30112186074256897}, {'word': ' слухе', 'start': 80.88, 'end': 81.16, 'probability': 0.7049875557422638}, {'word': ' своей', 'start': 81.16, 'end': 81.44, 'probability': 0.37969738245010376}, {'word': ' телевидей.', 'start': 81.44, 'end': 81.9, 'probability': 0.3175123644371827}]}, {'id': 25, 'seek': 5574, 'start': 82.0, 'end': 83.42, 'text': ' Она, ну, нашел сходить.', 'tokens': [51665, 20280, 11, 13087, 11, 8253, 1414, 776, 5280, 3258, 13, 51765], 'temperature': 0.0, 'avg_logprob': -0.8494445598678083, 'compression_ratio': 1.9682539682539681, 'no_speech_prob': 2.3881209509912793e-11, 'words': [{'word': ' Она,', 'start': 82.0, 'end': 82.24, 'probability': 0.9901185631752014}, {'word': ' ну,', 'start': 82.6, 'end': 82.7, 'probability': 0.43552812933921814}, {'word': ' нашел', 'start': 82.7, 'end': 83.06, 'probability': 0.5263556241989136}, {'word': ' сходить.', 'start': 83.06, 'end': 83.42, 'probability': 0.3637091666460037}]}, {'id': 26, 'seek': 8342, 'start': 83.42, 'end': 86.64, 'text': ' У нас один магазин.', 'tokens': [50415, 6523, 6519, 13319, 39771, 2599, 13, 50535], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' У', 'start': 83.42, 'end': 84.3, 'probability': 0.03252842649817467}, {'word': ' нас', 'start': 84.3, 'end': 85.72, 'probability': 0.9512675404548645}, {'word': ' один', 'start': 85.72, 'end': 86.22, 'probability': 0.1957031637430191}, {'word': ' магазин.', 'start': 86.22, 'end': 86.64, 'probability': 0.536332655698061}]}, {'id': 27, 'seek': 8342, 'start': 87.32, 'end': 88.84, 'text': ' Получается, один магазин.', 'tokens': [50552, 28183, 4187, 6970, 11, 13319, 39771, 2599, 13, 50635], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' Получается,', 'start': 87.32, 'end': 88.0, 'probability': 0.8084710935751597}, {'word': ' один', 'start': 88.02, 'end': 88.34, 'probability': 0.9188287854194641}, {'word': ' магазин.', 'start': 88.34, 'end': 88.84, 'probability': 0.9474816024303436}]}, {'id': 28, 'seek': 8342, 'start': 89.06, 'end': 89.22, 'text': ' Можно?', 'tokens': [50643, 34423, 30, 50657], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' Можно?', 'start': 89.06, 'end': 89.22, 'probability': 0.5598357319831848}]}, {'id': 29, 'seek': 8342, 'start': 89.82, 'end': 90.6, 'text': ' Да, конечно.', 'tokens': [50691, 9149, 11, 15271, 13, 50726], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' Да,', 'start': 89.82, 'end': 90.2, 'probability': 0.9862096905708313}, {'word': ' конечно.', 'start': 90.6, 'end': 90.6, 'probability': 0.9980251789093018}]}, {'id': 30, 'seek': 8342, 'start': 91.82, 'end': 94.1, 'text': ' Можно хозяйская, а здесь детская.', 'tokens': [50786, 34423, 49791, 1644, 28794, 11, 2559, 9087, 15079, 28794, 13, 50899], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' Можно', 'start': 91.82, 'end': 92.5, 'probability': 0.36941978335380554}, {'word': ' хозяйская,', 'start': 92.5, 'end': 93.18, 'probability': 0.6907058457533518}, {'word': ' а', 'start': 93.32, 'end': 93.38, 'probability': 0.2871646285057068}, {'word': ' здесь', 'start': 93.38, 'end': 93.48, 'probability': 0.274491548538208}, {'word': ' детская.', 'start': 93.48, 'end': 94.1, 'probability': 0.8098742961883545}]}, {'id': 31, 'seek': 8342, 'start': 94.3, 'end': 96.4, 'text': ' В детской стороне у нас хэпо,', 'tokens': [50922, 2348, 15079, 17360, 17635, 387, 1595, 6519, 3490, 7570, 1354, 354, 11, 51013], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' В', 'start': 94.3, 'end': 94.68, 'probability': 0.01484091579914093}, {'word': ' детской', 'start': 94.68, 'end': 95.0, 'probability': 0.9782683551311493}, {'word': ' стороне', 'start': 95.0, 'end': 95.44, 'probability': 0.9477444887161255}, {'word': ' у', 'start': 95.44, 'end': 95.6, 'probability': 0.9828675985336304}, {'word': ' нас', 'start': 95.6, 'end': 95.78, 'probability': 0.999481737613678}, {'word': ' хэпо,', 'start': 95.78, 'end': 96.4, 'probability': 0.4111717939376831}]}, {'id': 32, 'seek': 8342, 'start': 96.42, 'end': 97.76, 'text': ' где-то на 2 кг.', 'tokens': [51018, 11418, 12, 860, 1470, 568, 981, 1906, 13, 51087], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' где', 'start': 96.42, 'end': 96.62, 'probability': 0.1401025801897049}, {'word': '-то', 'start': 96.62, 'end': 96.84, 'probability': 0.5196909792721272}, {'word': ' на', 'start': 96.84, 'end': 97.16, 'probability': 0.11279246211051941}, {'word': ' 2', 'start': 97.16, 'end': 97.54, 'probability': 0.064992755651474}, {'word': ' кг.', 'start': 97.54, 'end': 97.76, 'probability': 0.4312170743942261}]}, {'id': 33, 'seek': 8342, 'start': 98.12, 'end': 100.22, 'text': ' В пластинке и саду и для гостей.', 'tokens': [51102, 2348, 713, 32465, 2599, 8222, 1006, 776, 2601, 585, 1006, 5561, 6778, 982, 2345, 13, 51205], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' В', 'start': 98.12, 'end': 98.34, 'probability': 0.06607469916343689}, {'word': ' пластинке', 'start': 98.34, 'end': 98.84, 'probability': 0.25606980454176664}, {'word': ' и', 'start': 98.84, 'end': 99.12, 'probability': 0.17359474301338196}, {'word': ' саду', 'start': 99.12, 'end': 99.42, 'probability': 0.562552144130071}, {'word': ' и', 'start': 99.42, 'end': 99.58, 'probability': 0.1944437325000763}, {'word': ' для', 'start': 99.58, 'end': 99.7, 'probability': 0.21062175929546356}, {'word': ' гостей.', 'start': 99.7, 'end': 100.22, 'probability': 0.9364011685053507}]}, {'id': 34, 'seek': 8342, 'start': 100.64, 'end': 102.98, 'text': ' Здесь у нас кухня гостиная,', 'tokens': [51247, 23367, 1595, 6519, 981, 11576, 5151, 6778, 4756, 6323, 11, 51344], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' Здесь', 'start': 100.64, 'end': 101.32, 'probability': 0.9955984354019165}, {'word': ' у', 'start': 101.32, 'end': 101.54, 'probability': 0.9987414479255676}, {'word': ' нас', 'start': 101.54, 'end': 101.82, 'probability': 0.9998631477355957}, {'word': ' кухня', 'start': 101.82, 'end': 102.42, 'probability': 0.9608238736788431}, {'word': ' гостиная,', 'start': 102.42, 'end': 102.98, 'probability': 0.7775633533795675}]}, {'id': 35, 'seek': 8342, 'start': 103.12, 'end': 104.06, 'text': ' 58 кг.', 'tokens': [51348, 21786, 981, 1906, 13, 51401], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' 58', 'start': 103.12, 'end': 103.42, 'probability': 0.9299630522727966}, {'word': ' кг.', 'start': 103.42, 'end': 104.06, 'probability': 0.8684222102165222}]}, {'id': 36, 'seek': 8342, 'start': 104.76, 'end': 106.7, 'text': ' А с левой стороны кабинет,', 'tokens': [51425, 3450, 776, 2344, 42308, 28360, 46186, 2599, 1094, 11, 51530], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' А', 'start': 104.76, 'end': 105.3, 'probability': 0.35650479793548584}, {'word': ' с', 'start': 105.3, 'end': 105.52, 'probability': 0.9749556183815002}, {'word': ' левой', 'start': 105.52, 'end': 105.68, 'probability': 0.701392650604248}, {'word': ' стороны', 'start': 105.68, 'end': 106.02, 'probability': 0.9933241009712219}, {'word': ' кабинет,', 'start': 106.02, 'end': 106.7, 'probability': 0.9588884711265564}]}, {'id': 37, 'seek': 8342, 'start': 106.88, 'end': 107.66, 'text': ' по 7 кг.', 'tokens': [51536, 2801, 1614, 981, 1906, 13, 51578], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' по', 'start': 106.88, 'end': 107.02, 'probability': 0.17175719141960144}, {'word': ' 7', 'start': 107.02, 'end': 107.2, 'probability': 0.6460407376289368}, {'word': ' кг.', 'start': 107.2, 'end': 107.66, 'probability': 0.9221472442150116}]}, {'id': 38, 'seek': 8342, 'start': 108.1, 'end': 108.84, 'text': ' А с левой стороны кабинет,', 'tokens': [51578, 3450, 776, 2344, 42308, 28360, 46186, 2599, 1094, 11, 51601], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' А', 'start': 108.1, 'end': 108.7, 'probability': 0.36730852723121643}, {'word': ' с', 'start': 108.7, 'end': 108.84, 'probability': 0.5039716362953186}, {'word': ' левой', 'start': 108.84, 'end': 108.84, 'probability': 0.9539317190647125}, {'word': ' стороны', 'start': 108.84, 'end': 108.84, 'probability': 0.9920496344566345}, {'word': ' кабинет,', 'start': 108.84, 'end': 108.84, 'probability': 0.9859823981920878}]}, {'id': 39, 'seek': 8342, 'start': 108.84, 'end': 113.4, 'text': ' а с левой стороны кабинет.', 'tokens': [51601, 2559, 776, 2344, 42308, 28360, 46186, 2599, 1094, 13, 51604], 'temperature': 0.0, 'avg_logprob': -0.8115525926862445, 'compression_ratio': 2.209205020920502, 'no_speech_prob': 3.267166745479777e-11, 'words': [{'word': ' а', 'start': 108.84, 'end': 108.84, 'probability': 0.0019074571318924427}, {'word': ' с', 'start': 108.84, 'end': 109.08, 'probability': 0.158877894282341}, {'word': ' левой', 'start': 109.08, 'end': 109.44, 'probability': 0.8471316993236542}, {'word': ' стороны', 'start': 109.44, 'end': 113.4, 'probability': 0.954450786113739}, {'word': ' кабинет.', 'start': 113.4, 'end': 113.4, 'probability': 0.9607149759928385}]}, {'id': 40, 'seek': 11342, 'start': 116.56, 'end': 119.82, 'text': ' Это тоже к этой зоне относится или это уже другой домик?', 'tokens': [50415, 6684, 12251, 981, 14907, 1423, 25561, 44539, 8254, 8101, 2691, 7520, 27823, 13049, 3605, 30, 50665], 'temperature': 0.0, 'avg_logprob': -0.4901735517713759, 'compression_ratio': 1.2625, 'no_speech_prob': 3.628538094990752e-11, 'words': [{'word': ' Это', 'start': 116.56, 'end': 117.04, 'probability': 0.6016061305999756}, {'word': ' тоже', 'start': 117.04, 'end': 117.28, 'probability': 0.9644503593444824}, {'word': ' к', 'start': 117.28, 'end': 117.42, 'probability': 0.6694245338439941}, {'word': ' этой', 'start': 117.42, 'end': 117.58, 'probability': 0.9878580570220947}, {'word': ' зоне', 'start': 117.58, 'end': 117.88, 'probability': 0.990658164024353}, {'word': ' относится', 'start': 117.88, 'end': 118.3, 'probability': 0.9041792452335358}, {'word': ' или', 'start': 118.3, 'end': 118.44, 'probability': 0.5289118885993958}, {'word': ' это', 'start': 118.44, 'end': 118.68, 'probability': 0.8086930513381958}, {'word': ' уже', 'start': 118.68, 'end': 118.82, 'probability': 0.39836743474006653}, {'word': ' другой', 'start': 118.82, 'end': 119.06, 'probability': 0.9061031937599182}, {'word': ' домик?', 'start': 119.06, 'end': 119.82, 'probability': 0.9820096790790558}]}, {'id': 41, 'seek': 0, 'start': 120.0, 'end': 120.48, 'text': ' Ань, да?', 'tokens': [50367, 3450, 18399, 11, 8995, 30, 50417], 'temperature': 0.0, 'avg_logprob': -0.9046339458889432, 'compression_ratio': 1.118279569892473, 'no_speech_prob': 2.4036342360922447e-11, 'words': [{'word': ' Ань,', 'start': 120.0, 'end': 120.3, 'probability': 0.5080475062131882}, {'word': ' да?', 'start': 120.4, 'end': 120.48, 'probability': 0.976854145526886}]}, {'id': 42, 'seek': 0, 'start': 126.92, 'end': 128.7, 'text': ' Шашлычки, ребята, жарят.', 'tokens': [50707, 18428, 6835, 693, 21097, 2241, 11, 37678, 11, 2989, 2222, 4558, 13, 50807], 'temperature': 0.0, 'avg_logprob': -0.9046339458889432, 'compression_ratio': 1.118279569892473, 'no_speech_prob': 2.4036342360922447e-11, 'words': [{'word': ' Шашлычки,', 'start': 126.92, 'end': 127.62, 'probability': 0.8979502558708191}, {'word': ' ребята,', 'start': 127.62, 'end': 128.02, 'probability': 0.8363624811172485}, {'word': ' жарят.', 'start': 128.04, 'end': 128.7, 'probability': 0.9525924523671468}]}, {'id': 43, 'seek': 0, 'start': 129.14, 'end': 130.94, 'text': ' Баня, ты не смотришь баня.', 'tokens': [50807, 5697, 1416, 681, 11, 5991, 1725, 6871, 30936, 18263, 29049, 681, 13, 50917], 'temperature': 0.0, 'avg_logprob': -0.9046339458889432, 'compression_ratio': 1.118279569892473, 'no_speech_prob': 2.4036342360922447e-11, 'words': [{'word': ' Баня,', 'start': 129.14, 'end': 129.66, 'probability': 0.7833169400691986}, {'word': ' ты', 'start': 129.88, 'end': 130.02, 'probability': 0.062275711447000504}, {'word': ' не', 'start': 130.02, 'end': 130.22, 'probability': 0.05683545768260956}, {'word': ' смотришь', 'start': 130.22, 'end': 130.68, 'probability': 0.6407463153203329}, {'word': ' баня.', 'start': 130.68, 'end': 130.94, 'probability': 0.36508847028017044}]}, {'id': 44, 'seek': 3000, 'start': 154.88, 'end': 156.28, 'text': ' Душ.', 'tokens': [50415, 3401, 8288, 13, 50465], 'temperature': 0.2, 'avg_logprob': -1.3867899576822917, 'compression_ratio': 0.4666666666666667, 'no_speech_prob': 2.9935068313058366e-11, 'words': [{'word': ' Душ.', 'start': 154.88, 'end': 156.28, 'probability': 0.5937219709157944}]}]}, 'diarization': [{'start': 0.03096875, 'end': 0.047843750000000004, 'speaker': 'SPEAKER_00'}, {'start': 1.8703437500000002, 'end': 5.8697187500000005, 'speaker': 'SPEAKER_00'}, {'start': 6.46034375, 'end': 17.54721875, 'speaker': 'SPEAKER_00'}, {'start': 18.15471875, 'end': 19.79159375, 'speaker': 'SPEAKER_00'}, {'start': 21.32721875, 'end': 22.829093750000002, 'speaker': 'SPEAKER_00'}, {'start': 101.06159375, 'end': 104.84159375, 'speaker': 'SPEAKER_00'}, {'start': 104.97659375, 'end': 105.02721875, 'speaker': 'SPEAKER_00'}, {'start': 105.09471875000001, 'end': 107.03534375000001, 'speaker': 'SPEAKER_00'}, {'start': 113.97096875000001, 'end': 114.03846875, 'speaker': 'SPEAKER_00'}, {'start': 114.91596875, 'end': 115.47284375000001, 'speaker': 'SPEAKER_00'}, {'start': 116.83971875, 'end': 120.58596875, 'speaker': 'SPEAKER_00'}, {'start': 118.71284375, 'end': 119.72534375000001, 'speaker': 'SPEAKER_01'}, {'start': 126.81284375000001, 'end': 129.02346875, 'speaker': 'SPEAKER_00'}, {'start': 129.12471875, 'end': 131.36909375000002, 'speaker': 'SPEAKER_00'}, {'start': 133.17471875, 'end': 144.02534375000002, 'speaker': 'SPEAKER_00'}, {'start': 134.99721875, 'end': 136.53284375, 'speaker': 'SPEAKER_01'}, {'start': 136.66784375, 'end': 137.08971875, 'speaker': 'SPEAKER_01'}, {'start': 141.66284375, 'end': 141.96659375000002, 'speaker': 'SPEAKER_01'}, {'start': 144.12659375, 'end': 144.68346875, 'speaker': 'SPEAKER_00'}, {'start': 144.80159375, 'end': 145.67909375000002, 'speaker': 'SPEAKER_00'}, {'start': 155.97284375, 'end': 156.20909375000002, 'speaker': 'SPEAKER_00'}, {'start': 158.41971875000002, 'end': 162.01409375, 'speaker': 'SPEAKER_00'}, {'start': 164.74784375000002, 'end': 164.76471875000001, 'speaker': 'SPEAKER_00'}]}\n",
      "57: Process-transcription response status: 200\n",
      "57: Job updated with transcription, timestamp, and time_taken: 34.990924 seconds.\n",
      "57: Removed temporary file: C:\\Users\\Alex\\AppData\\Local\\Temp\\tmporc9otof.wav\n"
     ]
    }
   ],
   "source": [
    "final_results = asyncio.run(process_jobs(filtered_jobs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'job_id': 60,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/03/02/144323ec-025a-4034-a897-10d942666609.wav',\n",
       "  'size': 0.060004234313964844,\n",
       "  'status': 'transcribed',\n",
       "  'transcription': [{'speaker': 'SPEAKER_02',\n",
       "    'start': 0.5499999999999998,\n",
       "    'end': 2.9,\n",
       "    'text': ' Газпром Энергосбыт, оператор Оксана, здравствуйте.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_03',\n",
       "    'start': 3.84,\n",
       "    'end': 6.94,\n",
       "    'text': ' Здравствуйте. Мне бы показания счетчика передали.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_02',\n",
       "    'start': 7.38,\n",
       "    'end': 8.7,\n",
       "    'text': ' Лицевой счет называйте.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_03',\n",
       "    'start': 10.06,\n",
       "    'end': 17.26,\n",
       "    'text': ' Ага, так. 0,1, 3,0, 20, 3,19.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_00',\n",
       "    'start': 20.44,\n",
       "    'end': 21.72,\n",
       "    'text': ' Фамилию скажите.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_03',\n",
       "    'start': 22.88,\n",
       "    'end': 26.08,\n",
       "    'text': ' Имущенко Александр Ушевич. Извините, показания?',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_03',\n",
       "    'start': 27.48,\n",
       "    'end': 30.08,\n",
       "    'text': ' Показание 32, 231.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_01',\n",
       "    'start': 31.939999999999998,\n",
       "    'end': 34.62,\n",
       "    'text': ' 32, 231. Показание принято?',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_03',\n",
       "    'start': 36.18,\n",
       "    'end': 37.56,\n",
       "    'text': ' Спасибо за что-то.',\n",
       "    'overlap': ''}],\n",
       "  'transcribed_at': '2025-03-02 12:47:16',\n",
       "  'time_taken': 28.496237},\n",
       " {'job_id': 57,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono-stereo',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/a352a068-a7d8-476c-af1c-1bd0c9895c2e.MOV',\n",
       "  'size': 1618.7826070785522,\n",
       "  'status': 'transcribed',\n",
       "  'transcription': [{'speaker': 'SPEAKER_00',\n",
       "    'start': 6.260000000000001,\n",
       "    'end': 19.38,\n",
       "    'text': ' Дверь просто так нельзя открыть. Здесь есть такой магнитный замочек, надо приложить пальчик, тогда открывается. Нужно нажимать, надо просто приложить пальчик. Это что я предлагаю? Это собака, я хочу тебя не берет. У меня не нас не будет собак.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_00',\n",
       "    'start': 21.020000000000003,\n",
       "    'end': 22.74,\n",
       "    'text': ' Дверь с теплоразливым.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_00',\n",
       "    'start': 100.64,\n",
       "    'end': 107.02,\n",
       "    'text': ' Здесь у нас кухня гостиная, 58 кг. А с левой стороны кабинет, по',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_00',\n",
       "    'start': 116.56,\n",
       "    'end': 120.48,\n",
       "    'text': ' Это тоже к этой зоне относится или это уже другой домик? Ань, да?',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_00',\n",
       "    'start': 126.92,\n",
       "    'end': 130.94,\n",
       "    'text': ' Шашлычки, ребята, жарят. Баня, ты не смотришь баня.',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_00',\n",
       "    'start': 154.88,\n",
       "    'end': 156.28,\n",
       "    'text': ' Душ.',\n",
       "    'overlap': ''}],\n",
       "  'transcribed_at': '2025-03-02 12:47:23',\n",
       "  'time_taken': 34.990924},\n",
       " {'job_id': 58,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono-stereo',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/6338698c-fb2c-4029-af2d-a7b2f1ee524b.MOV',\n",
       "  'size': 4.728764533996582,\n",
       "  'status': 'transcribed',\n",
       "  'transcription': [{'speaker': 'SPEAKER_00',\n",
       "    'start': 0.0,\n",
       "    'end': 1.26,\n",
       "    'text': ' А чё морда такая злая?',\n",
       "    'overlap': ''},\n",
       "   {'speaker': 'SPEAKER_00',\n",
       "    'start': 2.98,\n",
       "    'end': 4.12,\n",
       "    'text': ' Пределить мне чё-то хочешь?',\n",
       "    'overlap': ''}],\n",
       "  'transcribed_at': '2025-03-02 12:47:16',\n",
       "  'time_taken': 28.023924},\n",
       " {'job_id': 59,\n",
       "  'added_at': '2025-03-02 12:32:43',\n",
       "  'source': 'golos-hub',\n",
       "  'source_data': {'format': 'mono-stereo',\n",
       "   'diarization': True,\n",
       "   'num_speakers': False,\n",
       "   'language': False},\n",
       "  'files': 'C:/Users/Alex/golos-hub-back/uploads/2025/02/04/e2796736-feb5-4f98-a7ed-0a80631fc21c.MOV',\n",
       "  'size': 3.990297317504883,\n",
       "  'status': 'error',\n",
       "  'transcription': [],\n",
       "  'transcribed_at': '2025-03-02 12:47:14',\n",
       "  'time_taken': 26.005598}]"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sqlite3\n",
    "\n",
    "DATABASE = \"./asr_queue.db\"\n",
    "\n",
    "def update_job_in_db(job: dict, db_path=DATABASE):\n",
    "    \"\"\"\n",
    "    Update a job in the 'jobs' table, storing a large transcription dict as JSON.\n",
    "    Adjust columns to fit your schema.\n",
    "    \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # Convert the transcription dict (or list) to a JSON string\n",
    "    transcription_data = job.get(\"transcription\")\n",
    "    if isinstance(transcription_data, (dict, list)):\n",
    "        transcription_data = json.dumps(transcription_data, ensure_ascii=False)\n",
    "    else:\n",
    "        # If it's already a string or None, leave it as is\n",
    "        # (Or convert to a string if you prefer to ensure consistent DB storage)\n",
    "        transcription_data = str(transcription_data) if transcription_data else None\n",
    "\n",
    "    # Build the SQL statement with the columns you want to update\n",
    "    sql = \"\"\"\n",
    "    UPDATE jobs\n",
    "    SET\n",
    "        size = ?,\n",
    "        status = ?,\n",
    "        transcription = ?,\n",
    "        transcribed_at = ?,\n",
    "        time_taken = ?\n",
    "    WHERE job_id = ?\n",
    "    \"\"\"\n",
    "\n",
    "    # Use parameter binding to avoid SQL injection\n",
    "    cursor.execute(\n",
    "        sql,\n",
    "        (\n",
    "            job.get(\"size\"),               # float or None\n",
    "            job.get(\"status\"),             # str or None\n",
    "            transcription_data,            # JSON string (TEXT column)\n",
    "            job.get(\"transcribed_at\"),     # str or None\n",
    "            job.get(\"time_taken\"),         # float or None\n",
    "            job[\"job_id\"],                 # primary key or unique ID\n",
    "        )\n",
    "    )\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(f\"Updated job_id {job['job_id']} in the database.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated job_id 60 in the database.\n",
      "Updated job_id 57 in the database.\n",
      "Updated job_id 58 in the database.\n",
      "Updated job_id 59 in the database.\n"
     ]
    }
   ],
   "source": [
    "for job_dict in final_results:\n",
    "    update_job_in_db(job_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Шутки за 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "races = ['🧑🏾','🧑🏽','🧑🏻','🧑🏿']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "races.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
